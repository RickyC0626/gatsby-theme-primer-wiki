<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.939e588ebf00f2e0297f.css" data-identity="gatsby-global-css">.tippy-box[data-animation=fade][data-state=hidden]{opacity:0}[data-tippy-root]{max-width:calc(100vw - 10px)}.tippy-box{background-color:#333;border-radius:4px;color:#fff;font-size:14px;line-height:1.4;outline:0;position:relative;transition-property:visibility,opacity,-webkit-transform;transition-property:transform,visibility,opacity;transition-property:transform,visibility,opacity,-webkit-transform}.tippy-box[data-placement^=top]>.tippy-arrow{bottom:0}.tippy-box[data-placement^=top]>.tippy-arrow:before{border-top-color:initial;border-width:8px 8px 0;bottom:-7px;left:0;-webkit-transform-origin:center top;transform-origin:center top}.tippy-box[data-placement^=bottom]>.tippy-arrow{top:0}.tippy-box[data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:initial;border-width:0 8px 8px;left:0;top:-7px;-webkit-transform-origin:center bottom;transform-origin:center bottom}.tippy-box[data-placement^=left]>.tippy-arrow{right:0}.tippy-box[data-placement^=left]>.tippy-arrow:before{border-left-color:initial;border-width:8px 0 8px 8px;right:-7px;-webkit-transform-origin:center left;transform-origin:center left}.tippy-box[data-placement^=right]>.tippy-arrow{left:0}.tippy-box[data-placement^=right]>.tippy-arrow:before{border-right-color:initial;border-width:8px 8px 8px 0;left:-7px;-webkit-transform-origin:center right;transform-origin:center right}.tippy-box[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.54,1.5,.38,1.11)}.tippy-arrow{color:#333;height:16px;width:16px}.tippy-arrow:before{border-color:transparent;border-style:solid;content:"";position:absolute}.tippy-content{padding:5px 9px;position:relative;z-index:1}.tippy-box[data-theme~=light]{background-color:#fff;box-shadow:0 0 20px 4px rgba(154,161,177,.15),0 4px 80px -8px rgba(36,40,47,.25),0 4px 4px -2px rgba(91,94,105,.15);color:#26323d}.tippy-box[data-theme~=light][data-placement^=top]>.tippy-arrow:before{border-top-color:#fff}.tippy-box[data-theme~=light][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#fff}.tippy-box[data-theme~=light][data-placement^=left]>.tippy-arrow:before{border-left-color:#fff}.tippy-box[data-theme~=light][data-placement^=right]>.tippy-arrow:before{border-right-color:#fff}.tippy-box[data-theme~=light]>.tippy-backdrop{background-color:#fff}.tippy-box[data-theme~=light]>.tippy-svg-arrow{fill:#fff}html{font-family:SF Pro SC,SF Pro Text,SF Pro Icons,PingFang SC,Helvetica Neue,Helvetica,Arial,sans-serif}body{word-wrap:break-word;-ms-hyphens:auto;-webkit-hyphens:auto;hyphens:auto;overflow-wrap:break-word;-ms-word-break:break-all;word-break:break-word}blockquote,body,dd,dt,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,html,iframe,legend,p,pre,textarea{margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:100%;font-weight:400}button,input,select{margin:0}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}img,video{height:auto;max-width:100%}iframe{border:0}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}</style><meta name="generator" content="Gatsby 3.12.0"/><style data-styled="" data-styled-version="5.3.0">.hcoYYI{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:14px;background-color:#005cc5;color:#ffffff;padding:16px;}/*!sc*/
.hcoYYI:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.hcoYYI:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bhsmYh{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;line-height:1;color:#ffffff;margin-right:16px;}/*!sc*/
.bhsmYh:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bhsmYh:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.eUMSQB{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#ffffff;}/*!sc*/
.eUMSQB:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.eUMSQB:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.dNECOn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;color:inherit;margin-left:24px;}/*!sc*/
.dNECOn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.dNECOn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.hNrChk{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#24292e;display:block;}/*!sc*/
.hNrChk:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.hNrChk:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.iBmcyt{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;}/*!sc*/
.iBmcyt:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.iBmcyt:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.draiCu{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:16px;display:inline-block;padding-top:4px;padding-bottom:4px;color:#586069;font-weight:medium;}/*!sc*/
.draiCu:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.draiCu:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.draiCu{font-size:14px;}}/*!sc*/
.kydbMn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;padding:8px;margin-left:-32px;color:#2f363d;}/*!sc*/
.kydbMn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kydbMn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.fWewSX{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.fWewSX:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fWewSX:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bclAhw{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.bclAhw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bclAhw:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bclAhw:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.jiMAyG{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;margin-bottom:4px;}/*!sc*/
.jiMAyG:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.jiMAyG:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
data-styled.g1[id="Link-sc-1brdqhf-0"]{content:"hcoYYI,bhsmYh,eUMSQB,dNECOn,hNrChk,iBmcyt,draiCu,kydbMn,fWewSX,bclAhw,jiMAyG,"}/*!sc*/
.fMyqIQ{z-index:20;width:auto;height:auto;-webkit-clip:auto;clip:auto;position:absolute;overflow:hidden;}/*!sc*/
.fMyqIQ:not(:focus){-webkit-clip:rect(1px,1px,1px,1px);clip:rect(1px,1px,1px,1px);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;width:1px;margin:-1px;padding:0;}/*!sc*/
data-styled.g2[id="skip-link__SkipLink-sc-1z0kjxc-0"]{content:"fMyqIQ,"}/*!sc*/
.gkRvDD{display:none;margin-left:8px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gkRvDD{display:inline;}}/*!sc*/
.behEry{font-weight:600;display:inline-block;margin-bottom:4px;}/*!sc*/
.ebhDkJ{font-weight:600;}/*!sc*/
.fbtryb:before{content:'[';color:#959da5;margin-right:1px;opacity:0.5;}/*!sc*/
.fbtryb:after{content:']';color:#959da5;opacity:0.5;margin-left:1px;}/*!sc*/
.fbtryb:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.eYnlOv:before{margin-right:2px;content:'[';color:#959da5;opacity:0.5;}/*!sc*/
.dNDjBz:after{margin-left:2px;content:']';color:#959da5;opacity:0.5;}/*!sc*/
.bikSBW{font-size:14px;color:#444d56;margin-top:4px;}/*!sc*/
data-styled.g4[id="Text-sc-1s3uzov-0"]{content:"gkRvDD,behEry,ebhDkJ,fbtryb,eYnlOv,dNDjBz,bikSBW,"}/*!sc*/
.hWMpfP{background-color:#ffffff;color:#24292e;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.etfTiI{top:0;z-index:1;position:-webkit-sticky;position:sticky;}/*!sc*/
.gxBhQZ{padding-left:16px;padding-right:16px;background-color:#24292e;color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:66px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gxBhQZ{padding-left:24px;padding-right:24px;}}/*!sc*/
.bFIlIE{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.hWjVUJ{margin-left:24px;display:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.hWjVUJ{display:block;}}/*!sc*/
.jyqrg{position:relative;}/*!sc*/
.sYKmk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.cpSbMw{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.cpSbMw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.hRAPrM{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.ioFHus{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.ioFHus{display:none;}}/*!sc*/
.bwociq{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;background-color:none;cursor:pointer;}/*!sc*/
.bwociq:hover{fill:rgba(255,255,255,0.7);color:rgba(255,255,255,0.7);}/*!sc*/
.bwociq svg{fill:rgba(255,255,255,0.7);}/*!sc*/
.dkAYKh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
.jJoPUf{color:#2f363d;background-color:#fafbfc;display:none;height:calc(100vh - 66px);min-width:260px;max-width:360px;position:-webkit-sticky;position:sticky;top:66px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.jJoPUf{display:block;}}/*!sc*/
.bofEBa{height:100%;border-style:solid;border-color:#e1e4e8;border-width:0;border-right-width:1px;border-radius:0;}/*!sc*/
.erCMck{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.gqMphN{padding:24px;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-top-width:1px;}/*!sc*/
.gfcHFT{margin-left:0;padding-top:4px;padding-bottom:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.kanhPD{margin-bottom:4px;margin-top:4px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.cWWGJy{color:#586069;font-weight:400;display:block;}/*!sc*/
.bCkTHX{padding-left:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
.bicbnc{margin-left:16px;padding-top:0;padding-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.hsHDpf{margin-bottom:0;margin-top:8px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.YYpGb{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
.jcXqAE{padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/
@media screen and (min-width:544px){.jcXqAE{padding:32px;}}/*!sc*/
@media screen and (min-width:768px){.jcXqAE{padding:40px;}}/*!sc*/
@media screen and (min-width:1012px){.jcXqAE{padding:48px;}}/*!sc*/
.fWFLOe{display:none;max-height:calc(100vh - 66px - 24px);position:-webkit-sticky;position:sticky;top:90px;width:220px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:40px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.fWFLOe{display:block;}}/*!sc*/
.dNoCtD{margin:0;padding:0;}/*!sc*/
.kJfdyq{padding-left:0;}/*!sc*/
.eqzAwh{padding-left:16px;}/*!sc*/
.ejaYSC{width:100%;max-width:960px;}/*!sc*/
.bZmuzz{margin-bottom:32px;background-color:#f6f8fa;display:block;border-width:1px;border-style:solid;border-color:#e1e4e8;border-radius:6px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.bZmuzz{display:none;}}/*!sc*/
.hdoRyz{padding:16px;}/*!sc*/
.ePSgtU{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.fiEpCu{padding:16px;border-top:1px solid;border-color:border.gray;}/*!sc*/
.kcFYCD{padding-left:16px;padding-right:16px;padding-top:24px;padding-bottom:24px;margin-top:24px;background-color:#f6f8fa;border-radius:6px;}/*!sc*/
.WreGk{margin-top:64px;padding-top:32px;padding-bottom:32px;border-style:solid;border-color:#e1e4e8;border-width:0;border-top-width:1px;border-radius:0;}/*!sc*/
.eQVcYH{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g5[id="Box-nv15kw-0"]{content:"hWMpfP,etfTiI,gxBhQZ,bFIlIE,hWjVUJ,jyqrg,sYKmk,cpSbMw,hRAPrM,ioFHus,bwociq,dkAYKh,jJoPUf,bofEBa,erCMck,gqMphN,gfcHFT,kanhPD,cWWGJy,bCkTHX,bicbnc,hsHDpf,YYpGb,jcXqAE,fWFLOe,dNoCtD,kJfdyq,eqzAwh,ejaYSC,bZmuzz,hdoRyz,ePSgtU,fiEpCu,kcFYCD,WreGk,eQVcYH,"}/*!sc*/
.kNqLJV{position:relative;display:inline-block;padding:6px 16px;font-family:inherit;font-weight:600;line-height:20px;white-space:nowrap;vertical-align:middle;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:6px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;font-size:14px;}/*!sc*/
.kNqLJV:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.kNqLJV:focus{outline:none;}/*!sc*/
.kNqLJV:disabled{cursor:default;}/*!sc*/
.kNqLJV:disabled svg{opacity:0.6;}/*!sc*/
data-styled.g6[id="ButtonBase-sc-181ps9o-0"]{content:"kNqLJV,"}/*!sc*/
.fyGPIN{color:#24292e;background-color:#fafbfc;border:1px solid rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.04),inset 0 1px 0 rgba(255,255,255,0.25);display:inline-block;background-color:transparent;padding-left:4px;padding-right:4px;padding-top:0;padding-bottom:4px;margin-left:4px;margin-right:4px;}/*!sc*/
.fyGPIN:hover{background-color:#f3f4f6;border-color:rgba(27,31,35,0.15);}/*!sc*/
.fyGPIN:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
.fyGPIN:active{background-color:hsla(220,14%,94%,1);box-shadow:inset 0 0.15em 0.3em rgba(27,31,35,0.15);}/*!sc*/
.fyGPIN:disabled{color:#959da5;background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
@media screen and (min-width:544px){.fyGPIN{display:inline-block;}}/*!sc*/
@media screen and (min-width:768px){.fyGPIN{display:inline-block;}}/*!sc*/
@media screen and (min-width:1012px){.fyGPIN{display:none;}}/*!sc*/
data-styled.g7[id="Button-xjtz72-0"]{content:"fyGPIN,"}/*!sc*/
.iMUfwd{margin-right:8px;color:#6a737d;top:-3px;position:relative;}/*!sc*/
.dirTPa{margin-right:8px;}/*!sc*/
data-styled.g8[id="StyledOcticon-uhnt7w-0"]{content:"ccmZUE,iMUfwd,dirTPa,"}/*!sc*/
.cRbSBD{font-weight:600;font-size:32px;margin:0;}/*!sc*/
.gQDpKH{font-weight:600;font-size:32px;margin:0;font-size:16px;margin-bottom:16px;color:#6a737d;}/*!sc*/
data-styled.g12[id="Heading-sc-1cjoo9h-0"]{content:"cRbSBD,gQDpKH,"}/*!sc*/
.dABgSo{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.dABgSo:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.dABgSo:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.dABgSo:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.dABgSo:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.gTTyEa{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);}/*!sc*/
.gTTyEa:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.gTTyEa:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.gTTyEa:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.gTTyEa:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.cBojNI{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.cBojNI:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.cBojNI:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.cBojNI:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.cBojNI:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
data-styled.g13[id="ButtonOutline-sc-15gta9l-0"]{content:"dABgSo,gTTyEa,cBojNI,"}/*!sc*/
.ghqbdb{color:rgba(255,255,255,0.7);background-color:transparent;border:1px solid #444d56;box-shadow:none;}/*!sc*/
data-styled.g14[id="dark-button__DarkButton-sc-bvvmfe-0"]{content:"ghqbdb,"}/*!sc*/
.iNJUGh{border:0;font-size:inherit;font-family:inherit;background-color:transparent;-webkit-appearance:none;color:inherit;width:100%;}/*!sc*/
.iNJUGh:focus{outline:0;}/*!sc*/
data-styled.g15[id="TextInput__Input-sc-1apmpmt-0"]{content:"iNJUGh,"}/*!sc*/
.eGxJgu{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;min-height:34px;font-size:14px;line-height:20px;color:#24292e;vertical-align:middle;background-repeat:no-repeat;background-position:right 8px center;border:1px solid #e1e4e8;border-radius:6px;outline:none;box-shadow:inset 0 1px 0 rgba(225,228,232,0.2);padding:6px 12px;width:240px;}/*!sc*/
.eGxJgu .TextInput-icon{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#959da5;margin:0 8px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}/*!sc*/
.eGxJgu:focus-within{border-color:#0366d6;box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
@media (min-width:768px){.eGxJgu{font-size:14px;}}/*!sc*/
data-styled.g16[id="TextInput__Wrapper-sc-1apmpmt-1"]{content:"eGxJgu,"}/*!sc*/
.cVQXPh{font-size:16px !important;color:rgba(255,255,255,0.7);background-color:rgba(255,255,255,0.07);border:1px solid transparent;box-shadow:none;}/*!sc*/
.cVQXPh:focus{border:1px solid #444d56 outline:none;box-shadow:none;}/*!sc*/
data-styled.g17[id="dark-text-input__DarkTextInput-sc-1s2iwzn-0"]{content:"cVQXPh,"}/*!sc*/
.fgkVQD.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g19[id="nav-items__NavLink-sc-tqz5wl-0"]{content:"fgkVQD,"}/*!sc*/
.lcMKXT.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g20[id="nav-items__NavBox-sc-tqz5wl-1"]{content:"lcMKXT,"}/*!sc*/
.jojuSi{margin-top:24px;margin-bottom:16px;-webkit-scroll-margin-top:90px;-moz-scroll-margin-top:90px;-ms-scroll-margin-top:90px;scroll-margin-top:90px;}/*!sc*/
.jojuSi .octicon-link{visibility:hidden;}/*!sc*/
.jojuSi:hover .octicon-link,.jojuSi:focus-within .octicon-link{visibility:visible;}/*!sc*/
data-styled.g22[id="heading__StyledHeading-sc-1fu06k9-0"]{content:"jojuSi,"}/*!sc*/
.iEQqUA{margin-top:0;padding-bottom:4px;font-size:32px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g23[id="heading__StyledH1-sc-1fu06k9-1"]{content:"iEQqUA,"}/*!sc*/
.kLBshj{padding-bottom:4px;font-size:24px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g24[id="heading__StyledH2-sc-1fu06k9-2"]{content:"kLBshj,"}/*!sc*/
.clNcHj{padding-left:2em;margin-bottom:4px;}/*!sc*/
.clNcHj ul,.clNcHj ol{margin-top:0;margin-bottom:0;}/*!sc*/
.clNcHj li > p{margin-top:16px;}/*!sc*/
.clNcHj li + li{margin-top:8px;}/*!sc*/
data-styled.g32[id="list__List-sc-s5kxp2-0"]{content:"clNcHj,"}/*!sc*/
.ckqxGA{z-index:0;}/*!sc*/
data-styled.g37[id="layout___StyledBox-sc-7a5ttt-0"]{content:"ckqxGA,"}/*!sc*/
.bQueYM{margin-bottom:10px;}/*!sc*/
.bQueYM:before{content:"\2022";color:#6a737d;display:inline-block;width:16px;margin-left:-16px;}/*!sc*/
data-styled.g38[id="reference-li__ReferenceLi-sc-1rtyfvw-0"]{content:"bQueYM,"}/*!sc*/
.cNqnCg{list-style:none;}/*!sc*/
data-styled.g39[id="table-of-contents___StyledBox-sc-1jtv948-0"]{content:"cNqnCg,"}/*!sc*/
.fgqKUG{grid-area:table-of-contents;overflow:auto;}/*!sc*/
data-styled.g40[id="post-page___StyledBox-sc-17hbw1s-0"]{content:"fgqKUG,"}/*!sc*/
</style><title data-react-helmet="true">Reinforcement learning - Gatsby Theme Primer Wiki</title><meta data-react-helmet="true" name="description" content="Links Where to start learning Reinforcement Learning in 2018? Reinforcement Learning, An Introduction book  - Signif…"/><meta data-react-helmet="true" name="image" content="https://user-images.githubusercontent.com/10384315/53922681-2f6d3100-402a-11e9-9719-5d1811c8110a.png"/><meta data-react-helmet="true" property="og:title" content="Reinforcement learning"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:url" content="https://wiki.demo.owenyoung.com/machine-learning/reinforcement-learning/"/><meta data-react-helmet="true" property="og:image" content="https://user-images.githubusercontent.com/10384315/53922681-2f6d3100-402a-11e9-9719-5d1811c8110a.png"/><meta data-react-helmet="true" property="og:image:alt" content="A Gatsby theme for creating Primer wiki sites"/><meta data-react-helmet="true" property="og:site_name"/><meta data-react-helmet="true" property="og:description" content="Links Where to start learning Reinforcement Learning in 2018? Reinforcement Learning, An Introduction book  - Signif…"/><meta data-react-helmet="true" property="article:published_time" content="2021-08-13T21:12:02.000Z"/><meta data-react-helmet="true" property="article:modified_time" content="2021-08-21T19:30:25.000Z"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="article:section" content="None"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:title" content="Reinforcement learning"/><meta data-react-helmet="true" name="twitter:description" content="Links Where to start learning Reinforcement Learning in 2018? Reinforcement Learning, An Introduction book  - Signif…"/><meta data-react-helmet="true" name="twitter:image" content="https://user-images.githubusercontent.com/10384315/53922681-2f6d3100-402a-11e9-9719-5d1811c8110a.png"/><meta data-react-helmet="true" name="twitter:image:alt" content="A Gatsby theme for creating Primer wiki sites"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="icon" href="/favicon-32x32.png?v=f3da5bc9ee21801506bcf83c84f79ae4" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link as="script" rel="preload" href="/webpack-runtime-e630ae35d4e9aa0fd704.js"/><link as="script" rel="preload" href="/framework-1d3d9aa5e841da8133c8.js"/><link as="script" rel="preload" href="/bac1b955-c7037fb56cfc5cbde018.js"/><link as="script" rel="preload" href="/fba589a3-7e142401208b26326fdb.js"/><link as="script" rel="preload" href="/commons-d4c182a2050629043f01.js"/><link as="script" rel="preload" href="/app-cced7f1f6141af0d4cc8.js"/><link as="script" rel="preload" href="/component---theme-src-templates-post-query-js-4a3352054e86ce1ce39f.js"/><link as="fetch" rel="preload" href="/page-data/machine-learning/reinforcement-learning/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2220803758.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2320115945.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3495835395.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/451533639.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><a class="Link-sc-1brdqhf-0 hcoYYI skip-link__SkipLink-sc-1z0kjxc-0 fMyqIQ" color="auto.white" href="#skip-nav" font-size="1">Skip to content</a><div display="flex" color="text.primary" class="Box-nv15kw-0 hWMpfP"><div class="Box-nv15kw-0 etfTiI"><div display="flex" height="66" color="header.text" class="Box-nv15kw-0 gxBhQZ"><div display="flex" class="Box-nv15kw-0 bFIlIE"><a href="/" color="header.logo" class="Link-sc-1brdqhf-0 bhsmYh"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 ccmZUE" viewBox="0 0 16 16" width="32" height="32" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></a><a color="header.logo" font-family="mono" class="Link-sc-1brdqhf-0 eUMSQB" href="/">Wiki</a><div display="none,,,block" class="Box-nv15kw-0 hWjVUJ"><div role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-search-label" class="Box-nv15kw-0 jyqrg"><span class="TextInput__Wrapper-sc-1apmpmt-1 eGxJgu dark-text-input__DarkTextInput-sc-1s2iwzn-0 cVQXPh TextInput-wrapper" width="240"><input type="text" aria-autocomplete="list" aria-labelledby="downshift-search-label" autoComplete="off" value="" id="downshift-search-input" placeholder="Search Wiki" class="TextInput__Input-sc-1apmpmt-0 iNJUGh"/></span></div></div></div><div display="flex" class="Box-nv15kw-0 sYKmk"><div display="none,,,flex" class="Box-nv15kw-0 cpSbMw"><div display="flex" color="header.text" class="Box-nv15kw-0 hRAPrM"><a href="https://github.com/theowenyoung/gatsby-theme-primer-wiki" display="block" color="inherit" class="Link-sc-1brdqhf-0 dNECOn">Github</a></div><button aria-label="Theme" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV dABgSo ghqbdb"><svg aria-hidden="true" role="img" class="octicon octicon-sun" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z"></path></svg></button></div><div display="flex,,,none" class="Box-nv15kw-0 ioFHus"><button aria-label="Search" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV gTTyEa ghqbdb"><svg aria-hidden="true" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z"></path></svg></button></div><button aria-label="Show Graph Visualisation" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV cBojNI ghqbdb"><div title="Show Graph Visualisation" aria-label="Show Graph Visualisation" color="header.text" display="flex" class="Box-nv15kw-0 bwociq"><svg t="1607341341241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M512 512m-125.866667 0a125.866667 125.866667 0 1 0 251.733334 0 125.866667 125.866667 0 1 0-251.733334 0Z"></path><path d="M512 251.733333m-72.533333 0a72.533333 72.533333 0 1 0 145.066666 0 72.533333 72.533333 0 1 0-145.066666 0Z"></path><path d="M614.4 238.933333c0 4.266667 2.133333 8.533333 2.133333 12.8 0 19.2-4.266667 36.266667-12.8 51.2 81.066667 36.266667 138.666667 117.333333 138.666667 211.2C742.4 640 640 744.533333 512 744.533333s-230.4-106.666667-230.4-232.533333c0-93.866667 57.6-174.933333 138.666667-211.2-8.533333-14.933333-12.8-32-12.8-51.2 0-4.266667 0-8.533333 2.133333-12.8-110.933333 42.666667-189.866667 147.2-189.866667 273.066667 0 160 130.133333 292.266667 292.266667 292.266666S804.266667 672 804.266667 512c0-123.733333-78.933333-230.4-189.866667-273.066667z"></path><path d="M168.533333 785.066667m-72.533333 0a72.533333 72.533333 0 1 0 145.066667 0 72.533333 72.533333 0 1 0-145.066667 0Z"></path><path d="M896 712.533333m-61.866667 0a61.866667 61.866667 0 1 0 123.733334 0 61.866667 61.866667 0 1 0-123.733334 0Z"></path><path d="M825.6 772.266667c-74.666667 89.6-187.733333 147.2-313.6 147.2-93.866667 0-181.333333-32-249.6-87.466667-10.666667 19.2-25.6 34.133333-44.8 44.8C298.666667 942.933333 401.066667 981.333333 512 981.333333c149.333333 0 281.6-70.4 366.933333-177.066666-21.333333-4.266667-40.533333-17.066667-53.333333-32zM142.933333 684.8c-25.6-53.333333-38.4-110.933333-38.4-172.8C104.533333 288 288 104.533333 512 104.533333S919.466667 288 919.466667 512c0 36.266667-6.4 72.533333-14.933334 106.666667 23.466667 2.133333 42.666667 10.666667 57.6 25.6 12.8-42.666667 19.2-87.466667 19.2-132.266667 0-258.133333-211.2-469.333333-469.333333-469.333333S42.666667 253.866667 42.666667 512c0 74.666667 17.066667 142.933333 46.933333 204.8 14.933333-14.933333 32-27.733333 53.333333-32z"></path></svg><span display="none,,,inline" class="Text-sc-1s3uzov-0 gkRvDD">Show Graph Visualisation</span></div></button><div display="flex,,,none" class="Box-nv15kw-0 ioFHus"><button aria-label="Menu" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV dABgSo ghqbdb"><svg aria-hidden="true" role="img" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path></svg></button></div></div></div></div><div display="flex" class="Box-nv15kw-0 layout___StyledBox-sc-7a5ttt-0 dkAYKh ckqxGA"><div display="none,,,block" height="calc(100vh - 66px)" color="auto.gray.8" class="Box-nv15kw-0 jJoPUf"><div height="100%" style="overflow:auto" class="Box-nv15kw-0 bofEBa"><div display="flex" class="Box-nv15kw-0 erCMck"><div class="Box-nv15kw-0 gqMphN"><div display="flex" class="Box-nv15kw-0 erCMck"><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 cWWGJy lcMKXT" display="block">Meta</div><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/sharing/sharing/">Sharing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/ideas/ideas/">Ideas</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/focusing/focusing/">Focusing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/minimalism/minimalism/">Minimalism</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/research/research/">Research</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/knowledge/knowledge/">Knowledge</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/environment/environment/">Environment</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/music/music/">Music</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/life/life/">Life</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/writing/writing/">Writing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/macOS/macOS/">macOS</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/hardware/hardware/">Hardware</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/math/math/">Math</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/computer-science/computer-science/">Computer Science</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/programming/programming/">Programming</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/programming-languages/programming-languages/">Programming languages</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/data-science/data-science/">Data Science</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/open-source/open-source/">Open Source</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/languages/languages/">Languages</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/text-editors/text-editors/">Text editors</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/operating-systems/operating-systems/">Operating systems</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/package-managers/package-managers/">Package managers</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/devops/devops/">DevOps</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/mindfulness/mindfulness/">Mindfulness</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/compilers/compilers/">Compilers</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/physics/physics/">Physics</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/biology/biology/">Biology</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/automation/automation/">Automation</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/education/education/">Education</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/economy/economy/">Economy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/governance/governance/">Governance</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/consciousness/consciousness/">Consciousness</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/drugs/drugs/">Drugs</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/chemistry/chemistry/">Chemistry</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/unix/unix/">Unix</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/web/web/">Web</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/cloud-computing/cloud-computing/">Cloud computing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/front-end/front-end/">Front End</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/security/security/">Security</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/social-networks/social-networks/">Social networks</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/networking/networking/">Networking</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/health/health/">Health</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/fitness/fitness/">Fitness</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/medicine/medicine/">Medicine</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/history/history/">History</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/travel/travel/">Travel</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/geography/geography/">Geography</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/business/business/">Business</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/relationships/relationships/">Relationships</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/3d-printing/3d-printing/">3D Printing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/anki/anki/">Anki</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/philosophy/philosophy/">Philosophy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/video/video/">Video</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/machine-learning/machine-learning/">Machine learning</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/neural-networks/neural-networks/">Neural networks</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/unsupervised-learning/">Unsupervised learning</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a aria-current="page" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD active" display="block" sx="[object Object]" href="/machine-learning/reinforcement-learning/">Reinforcement learning</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/libraries/ml-libraries/">ML Libraries</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/datasets/">Datasets</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/ml-models/">ML Models</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/autonomous-driving/">Autonomous driving</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/artificial-intelligence/">Artificial intelligence</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/machine-learning/transfer-learning/">Transfer learning</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/computer-graphics/">Computer graphics</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/tools/tools/">Tools</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/design/design/">Design</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/keyboards/keyboards/">Keyboards</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/future/future/">Future</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/cryptocurrencies/cryptocurrencies/">Cryptocurrencies</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/privacy/privacy/">Privacy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/games/games/">Games</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/streaming/streaming/">Streaming</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/talks/talks/">Talks</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/analytics/analytics/">Analytics</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/databases/databases/">Databases</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/art/art/">Art</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/api/api/">API</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/distributed-systems/distributed-systems/">Distributed systems</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/backups/backups/">Backups</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/space/space/">Space</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/psychology/psychology/">Psychology</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/sleep/sleep/">Sleep</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/irc/irc/">IRC</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/work/work/">Work</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/management/management/">Management</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/latex/latex/">LaTeX</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/robots/robots/">Robots</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/nlp/nlp/">NLP</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/virtual-reality/virtual-reality/">Virtual Reality</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/augmented-reality/augmented-reality/">Augmented Reality</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/neuroscience/neuroscience/">Neuroscience</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/cli/cli/">CLI</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/humans/humans/">Humans</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/philanthropy/philanthropy/">Philanthropy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/animals/animals/">Animals</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/podcasts/podcasts/">Podcasts</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/documentaries/documentaries/">Documentaries</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/movies/movies/">Movies</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/tv-series/tv-series/">TV series</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/courses/courses/">Courses</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/articles/articles/">Articles</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/poems/poems/">Poems</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/research-papers/research-papers/">Research papers</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/books/books/">Books</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/other/other/">Other</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/notes/notes/">Notes</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/looking-back/looking-back/">Looking back</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div></div></div></div></div><main class="Box-nv15kw-0 YYpGb"><div id="skip-nav" display="flex" width="100%" class="Box-nv15kw-0 jcXqAE"><div display="none,,block" class="Box-nv15kw-0 post-page___StyledBox-sc-17hbw1s-0 fWFLOe fgqKUG"><span display="inline-block" font-weight="bold" class="Text-sc-1s3uzov-0 behEry">On this page</span><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 kJfdyq"><a display="inline-block" href="#reinforcement-learning" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Reinforcement learning</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 eqzAwh"><a display="inline-block" href="#links" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Links</a></li></ul></li></ul></div><div width="100%" class="Box-nv15kw-0 ejaYSC"><div display="block,,none" class="Box-nv15kw-0 bZmuzz"><div class="Box-nv15kw-0 hdoRyz"><div display="flex" class="Box-nv15kw-0 ePSgtU"><span font-weight="bold" class="Text-sc-1s3uzov-0 ebhDkJ">On this page</span></div></div><div class="Box-nv15kw-0 fiEpCu"><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 kJfdyq"><a display="inline-block" href="#reinforcement-learning" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Reinforcement learning</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 eqzAwh"><a display="inline-block" href="#links" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Links</a></li></ul></li></ul></div></div><h1 id="reinforcement-learning" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 cRbSBD jojuSi iEQqUA Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 cRbSBD jojuSi"><a href="#reinforcement-learning" color="auto.gray.8" aria-label="Reinforcement learning permalink" class="Link-sc-1brdqhf-0 kydbMn"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="http://en.wikipedia.org/wiki/Reinforcement_learning" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement learning</a></h1><h2 id="links" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 cRbSBD jojuSi kLBshj Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 cRbSBD jojuSi"><a href="#links" color="auto.gray.8" aria-label="Links permalink" class="Link-sc-1brdqhf-0 kydbMn"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Links</h2><ul class="list__List-sc-s5kxp2-0 clNcHj"><li><a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/7ui8jv/d_where_to_start_learning_reinforcement_learning/" class="Link-sc-1brdqhf-0 fWewSX">Where to start learning Reinforcement Learning in 2018?</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://mitpress.mit.edu/books/reinforcement-learning-second-edition" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning, An Introduction book</a> - Significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. (<a target="_blank" rel="noopener noreferrer" href="http://incompleteideas.net/book/the-book-2nd.html" class="Link-sc-1brdqhf-0 fWewSX">Web</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningAnIntroduction.jl" class="Link-sc-1brdqhf-0 fWewSX">Julia Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dennybritz/reinforcement-learning" class="Link-sc-1brdqhf-0 fWewSX">Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, TensorFlow. Exercises and Solutions to accompany Sutton&#x27;s Book and David Silver&#x27;s course.</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=WFCzLZKVs44" class="Link-sc-1brdqhf-0 fWewSX">Learning to Learn for Robotic Control - Prof. Pieter Abbeel</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=9EN_HoEk3KY" class="Link-sc-1brdqhf-0 fWewSX">MIT AGI: OpenAI Meta-Learning and Self-Play (Ilya Sutskever)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://mpatacchiola.github.io/blog/2016/12/09/dissecting-reinforcement-learning.html" class="Link-sc-1brdqhf-0 fWewSX">Dissecting Reinforcement Learning: Part 1</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.openai.com/learning-dexterity/" class="Link-sc-1brdqhf-0 fWewSX">Learning Dexterity (2018)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/google/dopamine" class="Link-sc-1brdqhf-0 fWewSX">Dopamine</a> - Research framework for fast prototyping of reinforcement learning algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/spinningup" class="Link-sc-1brdqhf-0 fWewSX">Spinning Up in Deep RL</a> - Educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL). (<a target="_blank" rel="noopener noreferrer" href="https://spinningup.openai.com/en/latest/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>) (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24184270" class="Link-sc-1brdqhf-0 fWewSX">HN</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Kaixhin/spinning-up-basic" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs" class="Link-sc-1brdqhf-0 fWewSX">Advanced Deep Learning &amp; Reinforcement Learning Course (2018)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/gym" class="Link-sc-1brdqhf-0 fWewSX">OpenAI Gym</a> - Toolkit for developing and comparing reinforcement learning algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python" class="Link-sc-1brdqhf-0 fWewSX">Hands-On Reinforcement Learning With Python book</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dalmia/David-Silver-Reinforcement-learning" class="Link-sc-1brdqhf-0 fWewSX">David Silver Reinforcement learning</a> - Notes for the Reinforcement Learning course by David Silver along with implementation of various algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/LantaoYu/MARL-Papers" class="Link-sc-1brdqhf-0 fWewSX">Paper Collection of Multi-Agent Reinforcement Learning (MARL)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/r0zetta/MARL" class="Link-sc-1brdqhf-0 fWewSX">MARL (Multi-Agent Reinforcement Learning Experiments)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://ray.readthedocs.io/en/latest/rllib.html" class="Link-sc-1brdqhf-0 fWewSX">RLlib</a> - Open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hill-a/stable-baselines" class="Link-sc-1brdqhf-0 fWewSX">Stable Baselines</a> - Set of improved implementations of reinforcement learning algorithms based on OpenAI Baselines.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ikostrikov/pytorch-a3c" class="Link-sc-1brdqhf-0 fWewSX">pytorch-a3c</a> - PyTorch implementation of Asynchronous Advantage Actor Critic (A3C) from &quot;Asynchronous Methods for Deep Reinforcement Learning&quot;.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=3N9phq_yZP0" class="Link-sc-1brdqhf-0 fWewSX">The Power of Self-Learning Systems (2019)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jason718/awesome-self-supervised-learning" class="Link-sc-1brdqhf-0 fWewSX">Awesome Self-Supervised Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Kaixhin/PlaNet" class="Link-sc-1brdqhf-0 fWewSX">PlaNet</a> - Deep Planning Network: Control from pixels by latent planning with learned dynamics.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hzwer/LearningToPaint" class="Link-sc-1brdqhf-0 fWewSX">Learning to Paint</a> - Painting AI that can reproduce paintings stroke by stroke using deep reinforcement learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://project.inria.fr/paiss/files/2018/07/zisserman-self-supervised.pdf" class="Link-sc-1brdqhf-0 fWewSX">Self-Supervised Learning</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=20195575" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/araffin/rl-baselines-zoo" class="Link-sc-1brdqhf-0 fWewSX">RL Baselines Zoo</a> - Collection of 100+ pre-trained RL agents using Stable Baselines, training and hyperparameter optimization included.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/bsuite" class="Link-sc-1brdqhf-0 fWewSX">bsuite</a> - Collection of carefully-designed experiments that investigate core capabilities of a reinforcement learning (RL) agent.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/open_spiel" class="Link-sc-1brdqhf-0 fWewSX">OpenSpiel</a> - Collection of environments and algorithms for research in general reinforcement learning and search/planning in games.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/slbo" class="Link-sc-1brdqhf-0 fWewSX">Stochastic Lower Bound Optimization</a> - Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/lightvector/KataGo" class="Link-sc-1brdqhf-0 fWewSX">KataGo</a> - Research and experimentation with self-play training in Go.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/catalyst-team/catalyst" class="Link-sc-1brdqhf-0 fWewSX">Catalyst</a> - Reproducible and fast DL &amp; RL.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=rOiaZ1hVb-A" class="Link-sc-1brdqhf-0 fWewSX">The Mathematics of AlphaGo (2019)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1707.03497" class="Link-sc-1brdqhf-0 fWewSX">Value Prediction Network (2017)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1911.08265" class="Link-sc-1brdqhf-0 fWewSX">Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/dzakrs/r_191108265_mastering_atari_go_chess_and_shogi_by/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>) (<a target="_blank" rel="noopener noreferrer" href="https://venturebeat.com/2019/11/20/deepminds-muzero-teaches-itself-how-to-win-at-atari-chess-shogi-and-go/" class="Link-sc-1brdqhf-0 fWewSX">Article</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sfujim/BCQ" class="Link-sc-1brdqhf-0 fWewSX">BCQ</a> - PyTorch implementation of BCQ for &quot;Off-Policy Deep Reinforcement Learning without Exploration&quot;.</li><li><a target="_blank" rel="noopener noreferrer" href="https://rltheorybook.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning: Theory and Algorithms</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=27565421" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/torchbeast" class="Link-sc-1brdqhf-0 fWewSX">TorchBeast</a> - PyTorch Platform for Distributed RL.</li><li><a target="_blank" rel="noopener noreferrer" href="https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/" class="Link-sc-1brdqhf-0 fWewSX">The Promise of Hierarchical Reinforcement Learning (2019)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/astooke/rlpyt" class="Link-sc-1brdqhf-0 fWewSX">rlpyt</a> - Reinforcement Learning in PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/astooke/accel_rl" class="Link-sc-1brdqhf-0 fWewSX">Accelerated Methods for Deep Reinforcement Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.acolyer.org/2020/01/15/programmatically-interpretable-reinforcement-learning/" class="Link-sc-1brdqhf-0 fWewSX">Programmatically interpretable reinforcement learning (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html" class="Link-sc-1brdqhf-0 fWewSX">Curriculum for Reinforcement Learning (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/rlax" class="Link-sc-1brdqhf-0 fWewSX">RLax</a> - Library built on top of JAX that exposes useful building blocks for implementing reinforcement learning agents.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kristery/Awesome-Imitation-Learning" class="Link-sc-1brdqhf-0 fWewSX">Curated list of awesome imitation learning resources and publications</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/medipixel/rl_algorithms" class="Link-sc-1brdqhf-0 fWewSX">Structural implementation of RL key algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/williamFalcon/DeepRLHacks" class="Link-sc-1brdqhf-0 fWewSX">DeepRLHacks</a> - Hacks for training RL systems from John Schulman&#x27;s lecture at Deep RL Bootcamp.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Machine-Learning-Tokyo/AI_Curriculum" class="Link-sc-1brdqhf-0 fWewSX">Open Deep Learning and Reinforcement Learning lectures from top Universities like Stanford University, MIT, UC Berkeley</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pranz24/pytorch-soft-actor-critic" class="Link-sc-1brdqhf-0 fWewSX">PyTorch implementation of soft actor critic</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/RobertTLange/deep-rl-tutorial" class="Link-sc-1brdqhf-0 fWewSX">Tutorial on Deep Reinforcement Learning in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mcgillmrl/prob_mbrl" class="Link-sc-1brdqhf-0 fWewSX">prob_mbrl</a> - Library of probabilistic model based RL algorithms in pytorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Tencent/PhoenixGo" class="Link-sc-1brdqhf-0 fWewSX">PhoenixGo</a> - Go AI program which implements the AlphaGo Zero paper.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tensortrade-org/tensortrade" class="Link-sc-1brdqhf-0 fWewSX">TensorTrade</a> - Trade Efficiently with Reinforcement Learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://towardsdatascience.com/en-lightning-reinforcement-learning-a155c217c3de" class="Link-sc-1brdqhf-0 fWewSX">En-Lightning Reinforcement Learning (2020)</a> - Building a DQN with PyTorch Lightning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvwerra/trl" class="Link-sc-1brdqhf-0 fWewSX">Transformer Reinforcement Learning</a> - Train transformer language models with reinforcement learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=x5Q79XCxMVc" class="Link-sc-1brdqhf-0 fWewSX">David Silver - Deep Reinforcement Learning from AlphaGo to AlphaStar (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jonathan-laurent/AlphaZero.jl" class="Link-sc-1brdqhf-0 fWewSX">AlphaZero.jl</a> - Generic, simple and fast implementation of Deepmind&#x27;s AlphaZero algorithm. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23599278" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/multiagent-particle-envs" class="Link-sc-1brdqhf-0 fWewSX">Multi-Agent Particle Environment</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2004.04136" class="Link-sc-1brdqhf-0 fWewSX">CURL: Contrastive Unsupervised Representations for Reinforcement Learning (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/MishaLaskin/curl" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cmu.edu/%7Eninamf/pubs-by-year.html" class="Link-sc-1brdqhf-0 fWewSX">Maria-Florina Balcan&#x27;s publications</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.googleblog.com/2020/04/an-optimistic-perspective-on-offline.html" class="Link-sc-1brdqhf-0 fWewSX">An Optimistic Perspective on Offline Reinforcement Learning (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://bair.berkeley.edu/blog/2020/12/07/offline/" class="Link-sc-1brdqhf-0 fWewSX">Offline Reinforcement Learning: How Conservative Algorithms Can Enable New Applications (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/TensorSwarm/TensorSwarm" class="Link-sc-1brdqhf-0 fWewSX">TensorSwarm</a> - Framework for reinforcement learning of robot swarms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/leonardblier/alrao" class="Link-sc-1brdqhf-0 fWewSX">Learning with Random Learning Rates in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/optimass/continual_learning_papers" class="Link-sc-1brdqhf-0 fWewSX">Continual Learning Literature</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2002.11523" class="Link-sc-1brdqhf-0 fWewSX">Using Reinforcement Learning in the Algorithmic Trading Problem (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23022864" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://bair.berkeley.edu/blog/2020/05/01/umrl/" class="Link-sc-1brdqhf-0 fWewSX">Unsupervised Meta-Learning: Learning to Learn without Supervision (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/scikit-learn-contrib/metric-learn" class="Link-sc-1brdqhf-0 fWewSX">metric-learn</a> - Metric Learning in Python.</li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/view/data-regularized-q" class="Link-sc-1brdqhf-0 fWewSX">Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/denisyarats/drq" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorlayer/RLzoo" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning Zoo</a> - Collection of the most practical reinforcement learning algorithms, frameworks and applications.</li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.einstein.ai/the-ai-economist/" class="Link-sc-1brdqhf-0 fWewSX">The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2004.13332" class="Link-sc-1brdqhf-0 fWewSX">Paper</a>) (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/RichardSocher/status/1255554801510674432" class="Link-sc-1brdqhf-0 fWewSX">Twitter</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/doerlbh/mentalRL" class="Link-sc-1brdqhf-0 fWewSX">mentalRL</a> - A Story of Two Streams: Reinforcement Learning Models from Human Behavior and Neuropsychiatry.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rolyatmax/tictactoe" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning With TicTacToe</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/NervanaSystems/coach" class="Link-sc-1brdqhf-0 fWewSX">Coach</a> - Python reinforcement learning framework containing implementation of many state-of-the-art algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://papers.nips.cc/paper/9556-reinforcement-learning-with-convex-constraints.pdf" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning with Convex Constraints (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/xkianteb/ApproPO" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://deepmind.com/research/publications/Acme" class="Link-sc-1brdqhf-0 fWewSX">Acme: A new framework for distributed reinforcement learning | DeepMind (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/acme" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hardmaru/slimevolleygym" class="Link-sc-1brdqhf-0 fWewSX">Slime Volleyball Gym Environment</a> - Simple OpenAI Gym environment for single and multi-agent reinforcement learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/eleurent/phd-bibliography" class="Link-sc-1brdqhf-0 fWewSX">References on Optimal Control, Reinforcement Learning and Motion Planning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/nle" class="Link-sc-1brdqhf-0 fWewSX">NetHack Learning Environment (NLE)</a> - Reinforcement Learning environment based on NetHack 3.6.</li><li><a target="_blank" rel="noopener noreferrer" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Rao_RL-CycleGAN_Reinforcement_Learning_Aware_Simulation-to-Real_CVPR_2020_paper.pdf" class="Link-sc-1brdqhf-0 fWewSX">RL-CycleGAN: Reinforcement Learning Aware Simulation-To-Real (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2004.07928" class="Link-sc-1brdqhf-0 fWewSX">MARLeME: A Multi-Agent Reinforcement Learning Model Extraction Library (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/maximecb/gym-minigrid" class="Link-sc-1brdqhf-0 fWewSX">Minimalistic Gridworld Environment (MiniGrid)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mfranzs/meta-learning-curiosity-algorithms" class="Link-sc-1brdqhf-0 fWewSX">Meta-Learning Curiosity Algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/eaplatanios/swift-rl" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning in Swift</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/dm_env" class="Link-sc-1brdqhf-0 fWewSX">dm_env</a> - DeepMind RL Environment API.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/SurrealAI/surreal" class="Link-sc-1brdqhf-0 fWewSX">SURREAL</a> - Fully integrated framework that runs state-of-the-art distributed reinforcement learning (RL) algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/reinforcementlearning/comments/hnebb8/i_need_suggestions_on_good_rl_courses/" class="Link-sc-1brdqhf-0 fWewSX">Suggestions of good RL courses (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2006.04734" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning Under Moral Uncertainty (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/hslstp/r_reinforcement_learning_under_moral_uncertainty/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/uber-research/normative-uncertainty" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1901.10995" class="Link-sc-1brdqhf-0 fWewSX">Go-Explore: a New Approach for Hard-Exploration Problems (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/uber-research/go-explore" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html" class="Link-sc-1brdqhf-0 fWewSX">Neural Architecture Search (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fabiopardo/qmap" class="Link-sc-1brdqhf-0 fWewSX">Scaling All-Goals Updates in Reinforcement Learning Using Convolutional Neural Networks</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fabiopardo/tonic" class="Link-sc-1brdqhf-0 fWewSX">Tonic</a> - Deep reinforcement learning library.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/WilsonWangTHU/mbbl" class="Link-sc-1brdqhf-0 fWewSX">Model Based Reinforcement Learning Benchmarking Library (MBBL)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/agents" class="Link-sc-1brdqhf-0 fWewSX">TF-Agents</a> - Reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.coursera.org/specializations/reinforcement-learning" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning Specialization by University of Alberta</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/optax" class="Link-sc-1brdqhf-0 fWewSX">Optax</a> - Gradient processing and optimization library for JAX.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/chex" class="Link-sc-1brdqhf-0 fWewSX">Chex</a> - Library of utilities for helping to write reliable JAX code.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2003.03600" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning for Combinatorial Optimization: A Survey (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/SforAiDl/genrl" class="Link-sc-1brdqhf-0 fWewSX">GenRL</a> - PyTorch reinforcement learning library centered around reproducible and generalizable algorithm implementations. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24292339" class="Link-sc-1brdqhf-0 fWewSX">HN</a>) (<a target="_blank" rel="noopener noreferrer" href="https://genrl.readthedocs.io/en/latest/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>) (<a target="_blank" rel="noopener noreferrer" href="https://genrl.readthedocs.io/en/latest/usage/tutorials/index.html" class="Link-sc-1brdqhf-0 fWewSX">Tutorials</a>) (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/reinforcementlearning/comments/ihibey/genrl_pytorchfirst_reinforcement_learning_library/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/DLR-RM/stable-baselines3" class="Link-sc-1brdqhf-0 fWewSX">Stable Baselines3</a> - PyTorch version of Stable Baselines, improved implementations of reinforcement learning algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorflow/minigo" class="Link-sc-1brdqhf-0 fWewSX">Minigo</a> - Minimalist Go engine modeled after AlphaGo Zero, built on MuGo.</li><li><a target="_blank" rel="noopener noreferrer" href="https://flowing.systems/2020/09/15/reinforcement-learning-non-markov-memory.html" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement learning, non-Markov environments, and memory (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://mathy.ai/" class="Link-sc-1brdqhf-0 fWewSX">Mathy</a> - Platform for using computer algebra systems to solve math problems step-by-step with reinforcement learning. (<a target="_blank" rel="noopener noreferrer" href="https://github.com/justindujardin/mathy/" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/maro" class="Link-sc-1brdqhf-0 fWewSX">Multi-Agent Resource Optimization (MARO)</a> - Instance of Reinforcement Learning as a Service (RaaS) for real-world resource optimization.</li><li><a target="_blank" rel="noopener noreferrer" href="https://hunch.net/?p=13762683" class="Link-sc-1brdqhf-0 fWewSX">Homer: Provable Exploration in Reinforcement Learning (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/datamllab/rlcard" class="Link-sc-1brdqhf-0 fWewSX">RLCard</a> - Toolkit for Reinforcement Learning in Card Games.</li><li><a target="_blank" rel="noopener noreferrer" href="https://simoninithomas.github.io/deep-rl-course/" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning Course (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/simoninithomas/Deep_reinforcement_learning_Course" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/cool-RR/grid_royale" class="Link-sc-1brdqhf-0 fWewSX">GridRoyale</a> - Life simulation for exploring social dynamics. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24744437" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/RchalYang/torchrl" class="Link-sc-1brdqhf-0 fWewSX">TorchRL</a> - PyTorch Implementation of Reinforcement Learning Algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://bair.berkeley.edu/blog/2020/10/13/supervised-rl/" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement learning is supervised learning on optimized data (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24771856" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/TianhongDai/reinforcement-learning-algorithms" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning Algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=xMZE-9WECQE" class="Link-sc-1brdqhf-0 fWewSX">Introduction to Reinforcement Learning (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/psc-g/intro_to_rl/blob/master/Introduction_to_reinforcement_learning.ipynb" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/ai-safety-gridworlds" class="Link-sc-1brdqhf-0 fWewSX">AI safety gridworlds</a> - Suite of reinforcement learning environments illustrating various safety properties of intelligent agents.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/EliorBenYosef/reinforcement-learning" class="Link-sc-1brdqhf-0 fWewSX">RL and Deep-RL implementations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://npdeep.github.io/cartpole-without-reinforcement-learning.html" class="Link-sc-1brdqhf-0 fWewSX">You don&#x27;t need reinforcement learning when you have basic physics (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24795953" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tensorlayer/tensorlayer" class="Link-sc-1brdqhf-0 fWewSX">TensorLayer</a> - Deep Learning and Reinforcement Learning Library for Scientists and Engineers. (<a target="_blank" rel="noopener noreferrer" href="https://tensorlayer.readthedocs.io/en/latest/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/FitMachineLearning/FitML" class="Link-sc-1brdqhf-0 fWewSX">FitML</a> - Collection of python Machine Learning articles and examples.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/greentfrapp/pysc2-RLagents" class="Link-sc-1brdqhf-0 fWewSX">Notes and scripts for SC2LE released by DeepMind and Blizzard</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pfnet/pfrl" class="Link-sc-1brdqhf-0 fWewSX">PFRL</a> - PyTorch-based deep reinforcement learning library.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/muupan/deep-reinforcement-learning-papers" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning Papers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/chainer/chainerrl" class="Link-sc-1brdqhf-0 fWewSX">ChainerRL</a> - Deep reinforcement learning library built on top of Chainer.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/impact-driven-exploration" class="Link-sc-1brdqhf-0 fWewSX">RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses" class="Link-sc-1brdqhf-0 fWewSX">Best Reinforcement Learning Tutorials, Examples, Projects, and Courses (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rasmusbergpalm/evostrat" class="Link-sc-1brdqhf-0 fWewSX">EvoStrat</a> - Library that makes Evolutionary Strategies (ES) simple to use.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/cgreer/alpha-zero-boosted" class="Link-sc-1brdqhf-0 fWewSX">Alpha Zero Boosted</a> - &quot;build to learn&quot; implementation of the Alpha Zero algorithm written in Python that uses LightGBM (Gradient Boosted Decision Trees) in place of a Deep Neural Network for value/policy functions.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/huawei-noah/xingtian" class="Link-sc-1brdqhf-0 fWewSX">XingTian</a> - Componentized library for the development and verification of reinforcement learning algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=_-aeyeBYz1s" class="Link-sc-1brdqhf-0 fWewSX">Theoretical Foundations of Reinforcement Learning (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/zuoxingdong/mazelab" class="Link-sc-1brdqhf-0 fWewSX">mazelab</a> - Customizable framework to create maze and gridworld environments.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sfujim/TD3" class="Link-sc-1brdqhf-0 fWewSX">Addressing Function Approximation Error in Actor-Critic Methods</a> - PyTorch implementation of Twin Delayed Deep Deterministic Policy Gradients (TD3).</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2007.08794" class="Link-sc-1brdqhf-0 fWewSX">Discovering Reinforcement Learning Algorithms (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mila-iqia/spr" class="Link-sc-1brdqhf-0 fWewSX">Data-Efficient Reinforcement Learning with Self-Predictive Representations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/lab2d" class="Link-sc-1brdqhf-0 fWewSX">DeepMind Lab2D</a> - Flexible and fast engine for rapidly creating 2D environments. Built for RL, and well suited for the needs of multi-agent research. (<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.07027" class="Link-sc-1brdqhf-0 fWewSX">Paper</a>) (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=25122080" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://distill.pub/2020/understanding-rl-vision/" class="Link-sc-1brdqhf-0 fWewSX">Understanding RL Vision (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/PettingZoo-Team/PettingZoo" class="Link-sc-1brdqhf-0 fWewSX">PettingZoo</a> - Python library for conducting research in multi-agent reinforcement learning. It&#x27;s akin to a multi-agent version of OpenAI&#x27;s Gym library.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/dm_hard_eight" class="Link-sc-1brdqhf-0 fWewSX">DeepMind Hard Eight Tasks</a> - Set of 8 diverse machine-learning tasks that require exploration in partially observable environments to solve.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jaybutera/tetrisRL" class="Link-sc-1brdqhf-0 fWewSX">TetrisRL</a> - Tetris environment to train machine learning agents.</li><li><a target="_blank" rel="noopener noreferrer" href="https://karpathy.github.io/2016/05/31/rl/" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning: Pong from Pixels (2016)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepmind/dm_env_rpc" class="Link-sc-1brdqhf-0 fWewSX">dm_env_rpc</a> - Networking protocol for agent-environment communication.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/phyre" class="Link-sc-1brdqhf-0 fWewSX">PHYRE</a> - Benchmark for physical reasoning. (<a target="_blank" rel="noopener noreferrer" href="https://phyre.ai/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/PettingZoo-Team/SuperSuit" class="Link-sc-1brdqhf-0 fWewSX">SuperSuit</a> - Easy-to-use micro-wrappers for Gym and PettingZoo based RL Environments.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mwydmuch/ViZDoom" class="Link-sc-1brdqhf-0 fWewSX">ViZDoom</a> - Doom-based AI Research Platform for Reinforcement Learning from Raw Visual Information. (<a target="_blank" rel="noopener noreferrer" href="http://vizdoom.cs.put.edu.pl/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.microsoft.com/en-us/research/blog/research-collection-reinforcement-learning-at-microsoft/" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning at Microsoft</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/banditml/banditml" class="Link-sc-1brdqhf-0 fWewSX">banditml</a> - Lightweight contextual bandit &amp; reinforcement learning library designed to be used in production Python services.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/LucasAlegre/sumo-rl" class="Link-sc-1brdqhf-0 fWewSX">SUMO-RL</a> - Provides a simple interface to instantiate Reinforcement Learning environments with SUMO for Traffic Signal Control.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Project-DC/pygeneses" class="Link-sc-1brdqhf-0 fWewSX">PyGeneses</a> - PyTorch based DeepRL framework to train and study artificial species in bio-inspired environments. (<a target="_blank" rel="noopener noreferrer" href="https://project-dc.github.io/docs/doc.html" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>) (<a target="_blank" rel="noopener noreferrer" href="https://medium.com/pytorch/pygeneses-a-deep-reinforcement-learning-framework-to-understand-complex-behaviour-b53aed0181f9" class="Link-sc-1brdqhf-0 fWewSX">Article</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://amid.fish/reproducing-deep-rl" class="Link-sc-1brdqhf-0 fWewSX">Lessons Learned Reproducing a Deep Reinforcement Learning Paper (2018)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/CompilerGym" class="Link-sc-1brdqhf-0 fWewSX">CompilerGym</a> - Reinforcement learning toolkit for compiler optimizations. (<a target="_blank" rel="noopener noreferrer" href="https://facebookresearch.github.io/CompilerGym/getting_started.html" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>) (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26001480" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver" class="Link-sc-1brdqhf-0 fWewSX">Introduction to Reinforcement Learning with David Silver</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/werner-duvaud/muzero-general" class="Link-sc-1brdqhf-0 fWewSX">MuZero General</a> - Commented and documented implementation of MuZero based on the Google DeepMind paper (Nov 2019) and the associated pseudocode.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.packtpub.com/product/deep-reinforcement-learning-hands-on-second-edition/9781838826994" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning Hands-On (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/rebel" class="Link-sc-1brdqhf-0 fWewSX">ReBeL</a> - Algorithm that generalizes the paradigm of self-play reinforcement learning and search to imperfect-information games.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/simondlevy/neat-gym" class="Link-sc-1brdqhf-0 fWewSX">NEAT Gym</a> - Learn OpenAI Gym environments using NEAT.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/rlstructures" class="Link-sc-1brdqhf-0 fWewSX">RLStructures</a> - Library to facilitate the implementation of new reinforcement learning algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/AI4Finance-LLC/FinRL-Library" class="Link-sc-1brdqhf-0 fWewSX">FinRL</a> - Deep Reinforcement Learning Library for Quantitative Finance.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/ReAgent" class="Link-sc-1brdqhf-0 fWewSX">ReAgent</a> - Platform for Reasoning systems (Reinforcement Learning, Contextual Bandits, etc.). (<a target="_blank" rel="noopener noreferrer" href="https://reagent.ai/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/RITCHIEHuang/DeepRL_Algorithms" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning Algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/MishaLaskin/curl" class="Link-sc-1brdqhf-0 fWewSX">CURL: Contrastive Unsupervised Representation Learning for Sample-Efficient Reinforcement Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/seungeunrho/minimalRL" class="Link-sc-1brdqhf-0 fWewSX">minimalRL PyTorch</a> - Implementations of basic RL algorithms with minimal lines of code.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/seungjaeryanlee/awesome-rl-competitions" class="Link-sc-1brdqhf-0 fWewSX">Awesome RL Competitions</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ntasfi/PyGame-Learning-Environment" class="Link-sc-1brdqhf-0 fWewSX">PyGame Learning Environment</a> - Reinforcement Learning Environment in Python.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/lusob/gym-ple" class="Link-sc-1brdqhf-0 fWewSX">OpenAI PLE environment</a> - Learning environment, mimicking the Arcade Learning Environment interface.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/AboudyKreidieh/h-baselines" class="Link-sc-1brdqhf-0 fWewSX">h-baselines</a> - High-performing hierarchical reinforcement learning models and algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://aihabitat.org/" class="Link-sc-1brdqhf-0 fWewSX">AI Habitat</a> - Simulation platform for research in Embodied AI. (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/habitat-challenge" class="Link-sc-1brdqhf-0 fWewSX">Habitat Challenge 2020 Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://jmvidal.cse.sc.edu/papers/mas.pdf" class="Link-sc-1brdqhf-0 fWewSX">Fundamentals of Multiagent Systems (2010)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vwxyzjn/cleanrl" class="Link-sc-1brdqhf-0 fWewSX">CleanRL</a> - High-quality single file implementation of Deep Reinforcement Learning algorithms with research-friendly features.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Curt-Park/rainbow-is-all-you-need" class="Link-sc-1brdqhf-0 fWewSX">Rainbow is all you need</a> - Step-by-step tutorial from DQN to Rainbow.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/mtenv" class="Link-sc-1brdqhf-0 fWewSX">MTEnv</a> - MultiTask Environments for Reinforcement Learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.googleblog.com/2021/02/mastering-atari-with-discrete-world.html" class="Link-sc-1brdqhf-0 fWewSX">Mastering Atari with Discrete World Models (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/denisyarats/proto" class="Link-sc-1brdqhf-0 fWewSX">Proto-RL: Reinforcement Learning with Prototypical Representations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://openreview.net/pdf?id=CGQ6ENUMX6" class="Link-sc-1brdqhf-0 fWewSX">Task-Agnostic Morphology Optimization (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/jhejna/morphology-opt" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sisl/MADRL" class="Link-sc-1brdqhf-0 fWewSX">MADRL</a> - Code for multi-agent deep reinforcement learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.02886" class="Link-sc-1brdqhf-0 fWewSX">Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/lili-chen/SEER" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence" class="Link-sc-1brdqhf-0 fWewSX">Self-supervised learning: The dark matter of intelligence (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/ylecun/status/1367516830542270467" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/reinforcementlearning/comments/lx50ao/examples_of_rl_applied_to_problems_that_arent/" class="Link-sc-1brdqhf-0 fWewSX">Examples of RL applied to problems that aren’t gaming/robotics? (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2007.04309" class="Link-sc-1brdqhf-0 fWewSX">Self-Supervised Policy Adaptation during Deployment (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/reinforcementlearning/comments/lxdiye/exploring_selfsupervised_policy_adaptation_to/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=SaJL4SLfrcY&amp;t=2532s" class="Link-sc-1brdqhf-0 fWewSX">Self-Supervised Learning - Yann LeCun (2019)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning: Introduction by Sutton and Barto</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://andyljones.com/posts/rl-debugging.html" class="Link-sc-1brdqhf-0 fWewSX">Debugging Reinforcement Learning Systems (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://clemenswinter.com/2021/03/24/mastering-real-time-strategy-games-with-deep-reinforcement-learning-mere-mortal-edition/" class="Link-sc-1brdqhf-0 fWewSX">Mastering Real-Time Strategy Games with Deep Reinforcement Learning: Mere Mortal Edition (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/heronsystems/adeptRL" class="Link-sc-1brdqhf-0 fWewSX">adeptRL</a> - Reinforcement learning framework to accelerate research.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/baselines" class="Link-sc-1brdqhf-0 fWewSX">OpenAI Baselines</a> - Set of high-quality implementations of reinforcement learning algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ikostrikov/jax-rl" class="Link-sc-1brdqhf-0 fWewSX">Jax (Flax) RL</a> - Jax (Flax) implementation of algorithms for Deep Reinforcement Learning with continuous action spaces.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=my207WNoeyA" class="Link-sc-1brdqhf-0 fWewSX">Markov Decision Processes (MDPs) - Structuring a Reinforcement Learning Problem (2018)</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://rail.eecs.berkeley.edu/deeprlcourse/" class="Link-sc-1brdqhf-0 fWewSX">Deep Reinforcement Learning Berkeley Course</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/berkeleydeeprlcourse/homework_fall2020" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/berkeleydeeprlcourse" class="Link-sc-1brdqhf-0 fWewSX">GitHub</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hanjuku-kaso/awesome-offline-rl" class="Link-sc-1brdqhf-0 fWewSX">Awesome Offline RL</a> - Collection of research and review papers for offline reinforcement learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.06272" class="Link-sc-1brdqhf-0 fWewSX">Podracer architectures for scalable Reinforcement Learning (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/jekbradbury/status/1382203188489588741" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/DLR-RM/rl-baselines3-zoo" class="Link-sc-1brdqhf-0 fWewSX">RL Baselines3 Zoo</a> - Training Framework for Stable Baselines3 Reinforcement Learning Agents.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/clvrai/awesome-rl-envs" class="Link-sc-1brdqhf-0 fWewSX">Awesome RL environments</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kengz/awesome-deep-rl" class="Link-sc-1brdqhf-0 fWewSX">Awesome Deep RL</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.notion.so/Paper-Notes-by-Vitaly-Kurin-97827e14e5cd4183815cfe3a5ecf2f4c" class="Link-sc-1brdqhf-0 fWewSX">Large collection of machine learning / RF paper notes</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ds4dm/ecole" class="Link-sc-1brdqhf-0 fWewSX">Ecole</a> - Extensible Combinatorial Optimization Learning Environments. (<a target="_blank" rel="noopener noreferrer" href="https://www.ecole.ai/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/mbrl-lib" class="Link-sc-1brdqhf-0 fWewSX">MBRL-Lib</a> - Library for Model Based RL.</li><li><a target="_blank" rel="noopener noreferrer" href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/" class="Link-sc-1brdqhf-0 fWewSX">Towards a Theory of Generalization in Reinforcement Learning (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.googleblog.com/2021/04/evolving-reinforcement-learning.html" class="Link-sc-1brdqhf-0 fWewSX">Evolving Reinforcement Learning Algorithms (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.googleblog.com/2021/04/model-based-rl-for-decentralized-multi.html" class="Link-sc-1brdqhf-0 fWewSX">Model-Based RL for Decentralized Multi-agent Navigation (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://danijar.com/project/dreamerv2/" class="Link-sc-1brdqhf-0 fWewSX">Mastering Atari with Discrete World Models (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/danijar/dreamerv2" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/google-research/robodesk" class="Link-sc-1brdqhf-0 fWewSX">RoboDesk</a> - Multi-Task Reinforcement Learning Benchmark.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl" class="Link-sc-1brdqhf-0 fWewSX">ReinforcementLearning.jl</a> - Reinforcement learning package for Julia. (<a target="_blank" rel="noopener noreferrer" href="https://juliareinforcementlearning.org/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1906.02771" class="Link-sc-1brdqhf-0 fWewSX">Improving Exploration in Soft-Actor-Critic with Normalizing Flows Policies (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/joeybose/FloRL" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/learnables/cherry" class="Link-sc-1brdqhf-0 fWewSX">Cherry</a> - PyTorch Library for Reinforcement Learning Research.</li><li><a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/berkeley.edu/decision-transformer" class="Link-sc-1brdqhf-0 fWewSX">Decision Transformer: Reinforcement Learning via Sequence Modeling (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/nqqle6/r_decision_transformer_reinforcement_learning_via/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>) (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/reinforcementlearning/comments/nqp9nh/decision_transformer_reinforcement_learning_via/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Miffyli/rl-human-prior-tricks" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning Tricks, Index</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://web.stanford.edu/class/cs234/index.html" class="Link-sc-1brdqhf-0 fWewSX">CS234: Reinforcement Learning Course</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Huixxi/CS234-Reinforcement-Learning-Winter-2019" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.01345" class="Link-sc-1brdqhf-0 fWewSX">Decision Transformer: Reinforcement Learning via Sequence Modeling (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/kzl/decision-transformer" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://rll.berkeley.edu/" class="Link-sc-1brdqhf-0 fWewSX">UC Berkeley Robot Learning Lab</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kzl/lifelong_rl" class="Link-sc-1brdqhf-0 fWewSX">lifelong_rl</a> - PyTorch implementations of RL algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.03273" class="Link-sc-1brdqhf-0 fWewSX">Control-Oriented Model-Based Reinforcement Learning with Implicit Differentiation (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/evgenii-nikishin/omd" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=4lthJd3DNTM" class="Link-sc-1brdqhf-0 fWewSX">Yann LeCun | The Energy-Based Learning Model (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://lilianweng.github.io/lil-log/" class="Link-sc-1brdqhf-0 fWewSX">Lil&#x27;Log</a> - Blog about RL.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Khrylx/PyTorch-RL" class="Link-sc-1brdqhf-0 fWewSX">PyTorch implementation of reinforcement learning algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rail-berkeley/d4rl" class="Link-sc-1brdqhf-0 fWewSX">D4RL: Datasets for Deep Data-Driven Reinforcement Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rlworkgroup/metaworld" class="Link-sc-1brdqhf-0 fWewSX">Meta-World</a> - Open source robotics benchmark for meta- and multi-task reinforcement learning. (<a target="_blank" rel="noopener noreferrer" href="https://meta-world.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rlworkgroup/garage" class="Link-sc-1brdqhf-0 fWewSX">garage</a> - Toolkit for reproducible reinforcement learning research.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.02039" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning as One Big Sequence Modeling Problem (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.davidsilver.uk/teaching/" class="Link-sc-1brdqhf-0 fWewSX">David Silver&#x27;s UCL Course on RL</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/instadeepai/Mava" class="Link-sc-1brdqhf-0 fWewSX">Mava</a> - Research framework for distributed multi-agent reinforcement learning. (<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/2107.01460.pdf" class="Link-sc-1brdqhf-0 fWewSX">Paper</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dredwardhyde/reinforcement-learning" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning Examples</a> - Policy Gradients, PPO+GAE, and DDQN Using OpenAI Gym and PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://openreview.net/forum?id=r-gPPHEjpmw" class="Link-sc-1brdqhf-0 fWewSX">Hierarchical Reinforcement Learning by Discovering Intrinsic Options</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/jesbu1/hidio" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://bair.berkeley.edu/blog/2021/07/08/basalt/" class="Link-sc-1brdqhf-0 fWewSX">BASALT: A Benchmark for Learning from Human Feedback (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/rohinmshah/status/1413185489335734277" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/google/brax" class="Link-sc-1brdqhf-0 fWewSX">BRAX</a> - Massively parallel rigidbody physics simulation on accelerator hardware.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.01151" class="Link-sc-1brdqhf-0 fWewSX">Towards Deeper Deep Reinforcement Learning (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/deep_bisim4control" class="Link-sc-1brdqhf-0 fWewSX">Learning Invariant Representations for Reinforcement Learning without Reconstruction</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/oxwhirl/pymarl" class="Link-sc-1brdqhf-0 fWewSX">Python MARL</a> - Python Multi-Agent Reinforcement Learning framework.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex-petrenko/sample-factory" class="Link-sc-1brdqhf-0 fWewSX">Sample Factory</a> - High throughput asynchronous reinforcement learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://deepmind.com/blog/article/generally-capable-agents-emerge-from-open-ended-play" class="Link-sc-1brdqhf-0 fWewSX">Generally capable agents emerge from open-ended play (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=27972950" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1912.01588" class="Link-sc-1brdqhf-0 fWewSX">Leveraging Procedural Generation to Benchmark Reinforcement Learning (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/procgen" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.freecodecamp.org/news/intro-to-advanced-actor-critic-methods-reinforcement-learning-course/" class="Link-sc-1brdqhf-0 fWewSX">Intro to Advanced Actor-Critic Methods: Reinforcement Learning Course (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/thu-ml/tianshou" class="Link-sc-1brdqhf-0 fWewSX">Tianshou</a> - Elegant PyTorch deep reinforcement learning library. (<a target="_blank" rel="noopener noreferrer" href="https://tianshou.readthedocs.io/en/master/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/lkwate/neural-question-generation" class="Link-sc-1brdqhf-0 fWewSX">Reinforcement Learning Generator-Evaluator Architecture for Question Generation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fabricerosay/AlphaGPU" class="Link-sc-1brdqhf-0 fWewSX">AlphaGPU</a> - Alphazero on GPU thanks to CUDA.jl.</li></ul><div class="Box-nv15kw-0 kcFYCD"><h4 font-size="2" color="text.placeholder" class="Heading-sc-1cjoo9h-0 gQDpKH"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 iMUfwd" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>LINKS TO THIS PAGE</h4><ul style="padding-left:16px;list-style:none" class="list__List-sc-s5kxp2-0 clNcHj"><li class="reference-li__ReferenceLi-sc-1rtyfvw-0 bQueYM"><span data-test="ref-tag" class="Text-sc-1s3uzov-0 fbtryb"><span class="Text-sc-1s3uzov-0 eYnlOv"></span><a sx="[object Object]" class="Link-sc-1brdqhf-0 bclAhw" href="/SUMMARY/">Summary</a><button display="inline-block,inline-block,inline-block,none" class="ButtonBase-sc-181ps9o-0 Button-xjtz72-0 kNqLJV fyGPIN"><svg aria-hidden="true" role="img" class="octicon octicon-zap" viewBox="0 0 16 16" width="14" height="14" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg></button><span class="Text-sc-1s3uzov-0 dNDjBz"></span></span></li></ul></div><div class="Box-nv15kw-0 WreGk"><div display="flex" class="Box-nv15kw-0 eQVcYH"><a href="https://github.com/theowenyoung/gatsby-theme-primer-wiki/tree/main/example/content/machine-learning/reinforcement-learning.md" class="Link-sc-1brdqhf-0 jiMAyG"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 dirTPa" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit this page</a><div><span font-size="1" color="auto.gray.7" class="Text-sc-1s3uzov-0 bikSBW">Last updated on<!-- --> <b>8/21/2021</b></span></div></div></div></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/machine-learning/reinforcement-learning/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-49a923993c744f4a3e64.js"],"app":["/app-cced7f1f6141af0d4cc8.js"],"component---theme-src-pages-404-js":["/component---theme-src-pages-404-js-384a8583460322aaad5b.js"],"component---theme-src-templates-post-query-js":["/component---theme-src-templates-post-query-js-4a3352054e86ce1ce39f.js"]};/*]]>*/</script><script src="/polyfill-49a923993c744f4a3e64.js" nomodule=""></script><script src="/component---theme-src-templates-post-query-js-4a3352054e86ce1ce39f.js" async=""></script><script src="/app-cced7f1f6141af0d4cc8.js" async=""></script><script src="/commons-d4c182a2050629043f01.js" async=""></script><script src="/fba589a3-7e142401208b26326fdb.js" async=""></script><script src="/bac1b955-c7037fb56cfc5cbde018.js" async=""></script><script src="/framework-1d3d9aa5e841da8133c8.js" async=""></script><script src="/webpack-runtime-e630ae35d4e9aa0fd704.js" async=""></script></body></html>