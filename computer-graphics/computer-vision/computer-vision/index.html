<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.939e588ebf00f2e0297f.css" data-identity="gatsby-global-css">.tippy-box[data-animation=fade][data-state=hidden]{opacity:0}[data-tippy-root]{max-width:calc(100vw - 10px)}.tippy-box{background-color:#333;border-radius:4px;color:#fff;font-size:14px;line-height:1.4;outline:0;position:relative;transition-property:visibility,opacity,-webkit-transform;transition-property:transform,visibility,opacity;transition-property:transform,visibility,opacity,-webkit-transform}.tippy-box[data-placement^=top]>.tippy-arrow{bottom:0}.tippy-box[data-placement^=top]>.tippy-arrow:before{border-top-color:initial;border-width:8px 8px 0;bottom:-7px;left:0;-webkit-transform-origin:center top;transform-origin:center top}.tippy-box[data-placement^=bottom]>.tippy-arrow{top:0}.tippy-box[data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:initial;border-width:0 8px 8px;left:0;top:-7px;-webkit-transform-origin:center bottom;transform-origin:center bottom}.tippy-box[data-placement^=left]>.tippy-arrow{right:0}.tippy-box[data-placement^=left]>.tippy-arrow:before{border-left-color:initial;border-width:8px 0 8px 8px;right:-7px;-webkit-transform-origin:center left;transform-origin:center left}.tippy-box[data-placement^=right]>.tippy-arrow{left:0}.tippy-box[data-placement^=right]>.tippy-arrow:before{border-right-color:initial;border-width:8px 8px 8px 0;left:-7px;-webkit-transform-origin:center right;transform-origin:center right}.tippy-box[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.54,1.5,.38,1.11)}.tippy-arrow{color:#333;height:16px;width:16px}.tippy-arrow:before{border-color:transparent;border-style:solid;content:"";position:absolute}.tippy-content{padding:5px 9px;position:relative;z-index:1}.tippy-box[data-theme~=light]{background-color:#fff;box-shadow:0 0 20px 4px rgba(154,161,177,.15),0 4px 80px -8px rgba(36,40,47,.25),0 4px 4px -2px rgba(91,94,105,.15);color:#26323d}.tippy-box[data-theme~=light][data-placement^=top]>.tippy-arrow:before{border-top-color:#fff}.tippy-box[data-theme~=light][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#fff}.tippy-box[data-theme~=light][data-placement^=left]>.tippy-arrow:before{border-left-color:#fff}.tippy-box[data-theme~=light][data-placement^=right]>.tippy-arrow:before{border-right-color:#fff}.tippy-box[data-theme~=light]>.tippy-backdrop{background-color:#fff}.tippy-box[data-theme~=light]>.tippy-svg-arrow{fill:#fff}html{font-family:SF Pro SC,SF Pro Text,SF Pro Icons,PingFang SC,Helvetica Neue,Helvetica,Arial,sans-serif}body{word-wrap:break-word;-ms-hyphens:auto;-webkit-hyphens:auto;hyphens:auto;overflow-wrap:break-word;-ms-word-break:break-all;word-break:break-word}blockquote,body,dd,dt,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,html,iframe,legend,p,pre,textarea{margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:100%;font-weight:400}button,input,select{margin:0}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}img,video{height:auto;max-width:100%}iframe{border:0}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}</style><meta name="generator" content="Gatsby 3.12.0"/><style data-styled="" data-styled-version="5.3.0">.hcoYYI{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:14px;background-color:#005cc5;color:#ffffff;padding:16px;}/*!sc*/
.hcoYYI:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.hcoYYI:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bhsmYh{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;line-height:1;color:#ffffff;margin-right:16px;}/*!sc*/
.bhsmYh:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bhsmYh:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.eUMSQB{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#ffffff;}/*!sc*/
.eUMSQB:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.eUMSQB:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.dNECOn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;color:inherit;margin-left:24px;}/*!sc*/
.dNECOn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.dNECOn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.hNrChk{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;color:#24292e;display:block;}/*!sc*/
.hNrChk:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.hNrChk:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.iBmcyt{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;display:block;}/*!sc*/
.iBmcyt:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.iBmcyt:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.draiCu{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;font-size:16px;display:inline-block;padding-top:4px;padding-bottom:4px;color:#586069;font-weight:medium;}/*!sc*/
.draiCu:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.draiCu:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.draiCu{font-size:14px;}}/*!sc*/
.kydbMn{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;padding:8px;margin-left:-32px;color:#2f363d;}/*!sc*/
.kydbMn:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.kydbMn:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.fWewSX{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.fWewSX:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.fWewSX:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bclAhw{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.bclAhw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.bclAhw:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
.bclAhw:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.jiMAyG{color:#0366d6;-webkit-text-decoration:none;text-decoration:none;margin-bottom:4px;}/*!sc*/
.jiMAyG:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/
.jiMAyG:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-color:transparent;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none;}/*!sc*/
data-styled.g1[id="Link-sc-1brdqhf-0"]{content:"hcoYYI,bhsmYh,eUMSQB,dNECOn,hNrChk,iBmcyt,draiCu,kydbMn,fWewSX,bclAhw,jiMAyG,"}/*!sc*/
.fMyqIQ{z-index:20;width:auto;height:auto;-webkit-clip:auto;clip:auto;position:absolute;overflow:hidden;}/*!sc*/
.fMyqIQ:not(:focus){-webkit-clip:rect(1px,1px,1px,1px);clip:rect(1px,1px,1px,1px);-webkit-clip-path:inset(50%);clip-path:inset(50%);height:1px;width:1px;margin:-1px;padding:0;}/*!sc*/
data-styled.g2[id="skip-link__SkipLink-sc-1z0kjxc-0"]{content:"fMyqIQ,"}/*!sc*/
.gkRvDD{display:none;margin-left:8px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gkRvDD{display:inline;}}/*!sc*/
.behEry{font-weight:600;display:inline-block;margin-bottom:4px;}/*!sc*/
.ebhDkJ{font-weight:600;}/*!sc*/
.fbtryb:before{content:'[';color:#959da5;margin-right:1px;opacity:0.5;}/*!sc*/
.fbtryb:after{content:']';color:#959da5;opacity:0.5;margin-left:1px;}/*!sc*/
.fbtryb:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.eYnlOv:before{margin-right:2px;content:'[';color:#959da5;opacity:0.5;}/*!sc*/
.dNDjBz:after{margin-left:2px;content:']';color:#959da5;opacity:0.5;}/*!sc*/
.bikSBW{font-size:14px;color:#444d56;margin-top:4px;}/*!sc*/
data-styled.g4[id="Text-sc-1s3uzov-0"]{content:"gkRvDD,behEry,ebhDkJ,fbtryb,eYnlOv,dNDjBz,bikSBW,"}/*!sc*/
.hWMpfP{background-color:#ffffff;color:#24292e;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.etfTiI{top:0;z-index:1;position:-webkit-sticky;position:sticky;}/*!sc*/
.gxBhQZ{padding-left:16px;padding-right:16px;background-color:#24292e;color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:66px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.gxBhQZ{padding-left:24px;padding-right:24px;}}/*!sc*/
.bFIlIE{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.hWjVUJ{margin-left:24px;display:none;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.hWjVUJ{display:block;}}/*!sc*/
.jyqrg{position:relative;}/*!sc*/
.sYKmk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.cpSbMw{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.cpSbMw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/
.hRAPrM{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.ioFHus{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.ioFHus{display:none;}}/*!sc*/
.bwociq{color:rgba(255,255,255,0.7);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;background-color:none;cursor:pointer;}/*!sc*/
.bwociq:hover{fill:rgba(255,255,255,0.7);color:rgba(255,255,255,0.7);}/*!sc*/
.bwociq svg{fill:rgba(255,255,255,0.7);}/*!sc*/
.dkAYKh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
.jJoPUf{color:#2f363d;background-color:#fafbfc;display:none;height:calc(100vh - 66px);min-width:260px;max-width:360px;position:-webkit-sticky;position:sticky;top:66px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){}/*!sc*/
@media screen and (min-width:1012px){.jJoPUf{display:block;}}/*!sc*/
.bofEBa{height:100%;border-style:solid;border-color:#e1e4e8;border-width:0;border-right-width:1px;border-radius:0;}/*!sc*/
.erCMck{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.gqMphN{padding:24px;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-top-width:1px;}/*!sc*/
.gfcHFT{margin-left:0;padding-top:4px;padding-bottom:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.kanhPD{margin-bottom:4px;margin-top:4px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.cWWGJy{color:#586069;font-weight:400;display:block;}/*!sc*/
.bCkTHX{padding-left:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/
.bicbnc{margin-left:16px;padding-top:0;padding-bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border-style:solid;border-color:#e1e4e8;border-width:0;border-radius:0;border-bottom-width:0;}/*!sc*/
.hsHDpf{margin-bottom:0;margin-top:8px;font-size:14px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
.YYpGb{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
.jcXqAE{padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/
@media screen and (min-width:544px){.jcXqAE{padding:32px;}}/*!sc*/
@media screen and (min-width:768px){.jcXqAE{padding:40px;}}/*!sc*/
@media screen and (min-width:1012px){.jcXqAE{padding:48px;}}/*!sc*/
.fWFLOe{display:none;max-height:calc(100vh - 66px - 24px);position:-webkit-sticky;position:sticky;top:90px;width:220px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:40px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.fWFLOe{display:block;}}/*!sc*/
.dNoCtD{margin:0;padding:0;}/*!sc*/
.kJfdyq{padding-left:0;}/*!sc*/
.eqzAwh{padding-left:16px;}/*!sc*/
.ejaYSC{width:100%;max-width:960px;}/*!sc*/
.bZmuzz{margin-bottom:32px;background-color:#f6f8fa;display:block;border-width:1px;border-style:solid;border-color:#e1e4e8;border-radius:6px;}/*!sc*/
@media screen and (min-width:544px){}/*!sc*/
@media screen and (min-width:768px){.bZmuzz{display:none;}}/*!sc*/
.hdoRyz{padding:16px;}/*!sc*/
.ePSgtU{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.fiEpCu{padding:16px;border-top:1px solid;border-color:border.gray;}/*!sc*/
.kcFYCD{padding-left:16px;padding-right:16px;padding-top:24px;padding-bottom:24px;margin-top:24px;background-color:#f6f8fa;border-radius:6px;}/*!sc*/
.WreGk{margin-top:64px;padding-top:32px;padding-bottom:32px;border-style:solid;border-color:#e1e4e8;border-width:0;border-top-width:1px;border-radius:0;}/*!sc*/
.eQVcYH{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g5[id="Box-nv15kw-0"]{content:"hWMpfP,etfTiI,gxBhQZ,bFIlIE,hWjVUJ,jyqrg,sYKmk,cpSbMw,hRAPrM,ioFHus,bwociq,dkAYKh,jJoPUf,bofEBa,erCMck,gqMphN,gfcHFT,kanhPD,cWWGJy,bCkTHX,bicbnc,hsHDpf,YYpGb,jcXqAE,fWFLOe,dNoCtD,kJfdyq,eqzAwh,ejaYSC,bZmuzz,hdoRyz,ePSgtU,fiEpCu,kcFYCD,WreGk,eQVcYH,"}/*!sc*/
.kNqLJV{position:relative;display:inline-block;padding:6px 16px;font-family:inherit;font-weight:600;line-height:20px;white-space:nowrap;vertical-align:middle;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:6px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-text-decoration:none;text-decoration:none;text-align:center;font-size:14px;}/*!sc*/
.kNqLJV:hover{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.kNqLJV:focus{outline:none;}/*!sc*/
.kNqLJV:disabled{cursor:default;}/*!sc*/
.kNqLJV:disabled svg{opacity:0.6;}/*!sc*/
data-styled.g6[id="ButtonBase-sc-181ps9o-0"]{content:"kNqLJV,"}/*!sc*/
.fyGPIN{color:#24292e;background-color:#fafbfc;border:1px solid rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.04),inset 0 1px 0 rgba(255,255,255,0.25);display:inline-block;background-color:transparent;padding-left:4px;padding-right:4px;padding-top:0;padding-bottom:4px;margin-left:4px;margin-right:4px;}/*!sc*/
.fyGPIN:hover{background-color:#f3f4f6;border-color:rgba(27,31,35,0.15);}/*!sc*/
.fyGPIN:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
.fyGPIN:active{background-color:hsla(220,14%,94%,1);box-shadow:inset 0 0.15em 0.3em rgba(27,31,35,0.15);}/*!sc*/
.fyGPIN:disabled{color:#959da5;background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
@media screen and (min-width:544px){.fyGPIN{display:inline-block;}}/*!sc*/
@media screen and (min-width:768px){.fyGPIN{display:inline-block;}}/*!sc*/
@media screen and (min-width:1012px){.fyGPIN{display:none;}}/*!sc*/
data-styled.g7[id="Button-xjtz72-0"]{content:"fyGPIN,"}/*!sc*/
.iMUfwd{margin-right:8px;color:#6a737d;top:-3px;position:relative;}/*!sc*/
.dirTPa{margin-right:8px;}/*!sc*/
data-styled.g8[id="StyledOcticon-uhnt7w-0"]{content:"ccmZUE,iMUfwd,dirTPa,"}/*!sc*/
.cRbSBD{font-weight:600;font-size:32px;margin:0;}/*!sc*/
.gQDpKH{font-weight:600;font-size:32px;margin:0;font-size:16px;margin-bottom:16px;color:#6a737d;}/*!sc*/
data-styled.g12[id="Heading-sc-1cjoo9h-0"]{content:"cRbSBD,gQDpKH,"}/*!sc*/
.dABgSo{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.dABgSo:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.dABgSo:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.dABgSo:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.dABgSo:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.gTTyEa{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);}/*!sc*/
.gTTyEa:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.gTTyEa:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.gTTyEa:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.gTTyEa:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
.cBojNI{color:#0366d6;border:1px solid rgba(27,31,35,0.15);background-color:#fafbfc;box-shadow:0 1px 0 rgba(27,31,35,0.04);margin-left:16px;}/*!sc*/
.cBojNI:hover{color:#ffffff;background-color:#0366d6;border-color:rgba(27,31,35,0.15);box-shadow:0 1px 0 rgba(27,31,35,0.1);}/*!sc*/
.cBojNI:focus{border-color:rgba(27,31,35,0.15);box-shadow:0 0 0 3px rgba(0,92,197,0.4);}/*!sc*/
.cBojNI:active{color:#ffffff;background-color:hsla(212,97%,40%,1);box-shadow:inset 0 1px 0 rgba(5,38,76,0.2);border-color:rgba(27,31,35,0.15);}/*!sc*/
.cBojNI:disabled{color:rgba(3,102,214,0.5);background-color:#fafbfc;border-color:rgba(27,31,35,0.15);}/*!sc*/
data-styled.g13[id="ButtonOutline-sc-15gta9l-0"]{content:"dABgSo,gTTyEa,cBojNI,"}/*!sc*/
.ghqbdb{color:rgba(255,255,255,0.7);background-color:transparent;border:1px solid #444d56;box-shadow:none;}/*!sc*/
data-styled.g14[id="dark-button__DarkButton-sc-bvvmfe-0"]{content:"ghqbdb,"}/*!sc*/
.iNJUGh{border:0;font-size:inherit;font-family:inherit;background-color:transparent;-webkit-appearance:none;color:inherit;width:100%;}/*!sc*/
.iNJUGh:focus{outline:0;}/*!sc*/
data-styled.g15[id="TextInput__Input-sc-1apmpmt-0"]{content:"iNJUGh,"}/*!sc*/
.eGxJgu{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;min-height:34px;font-size:14px;line-height:20px;color:#24292e;vertical-align:middle;background-repeat:no-repeat;background-position:right 8px center;border:1px solid #e1e4e8;border-radius:6px;outline:none;box-shadow:inset 0 1px 0 rgba(225,228,232,0.2);padding:6px 12px;width:240px;}/*!sc*/
.eGxJgu .TextInput-icon{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#959da5;margin:0 8px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}/*!sc*/
.eGxJgu:focus-within{border-color:#0366d6;box-shadow:0 0 0 3px rgba(3,102,214,0.3);}/*!sc*/
@media (min-width:768px){.eGxJgu{font-size:14px;}}/*!sc*/
data-styled.g16[id="TextInput__Wrapper-sc-1apmpmt-1"]{content:"eGxJgu,"}/*!sc*/
.cVQXPh{font-size:16px !important;color:rgba(255,255,255,0.7);background-color:rgba(255,255,255,0.07);border:1px solid transparent;box-shadow:none;}/*!sc*/
.cVQXPh:focus{border:1px solid #444d56 outline:none;box-shadow:none;}/*!sc*/
data-styled.g17[id="dark-text-input__DarkTextInput-sc-1s2iwzn-0"]{content:"cVQXPh,"}/*!sc*/
.fgkVQD.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g19[id="nav-items__NavLink-sc-tqz5wl-0"]{content:"fgkVQD,"}/*!sc*/
.lcMKXT.active{font-weight:600;color:#2f363d;}/*!sc*/
data-styled.g20[id="nav-items__NavBox-sc-tqz5wl-1"]{content:"lcMKXT,"}/*!sc*/
.jojuSi{margin-top:24px;margin-bottom:16px;-webkit-scroll-margin-top:90px;-moz-scroll-margin-top:90px;-ms-scroll-margin-top:90px;scroll-margin-top:90px;}/*!sc*/
.jojuSi .octicon-link{visibility:hidden;}/*!sc*/
.jojuSi:hover .octicon-link,.jojuSi:focus-within .octicon-link{visibility:visible;}/*!sc*/
data-styled.g22[id="heading__StyledHeading-sc-1fu06k9-0"]{content:"jojuSi,"}/*!sc*/
.iEQqUA{margin-top:0;padding-bottom:4px;font-size:32px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g23[id="heading__StyledH1-sc-1fu06k9-1"]{content:"iEQqUA,"}/*!sc*/
.kLBshj{padding-bottom:4px;font-size:24px;border-bottom:1px solid #e1e4e8;}/*!sc*/
data-styled.g24[id="heading__StyledH2-sc-1fu06k9-2"]{content:"kLBshj,"}/*!sc*/
.clNcHj{padding-left:2em;margin-bottom:4px;}/*!sc*/
.clNcHj ul,.clNcHj ol{margin-top:0;margin-bottom:0;}/*!sc*/
.clNcHj li > p{margin-top:16px;}/*!sc*/
.clNcHj li + li{margin-top:8px;}/*!sc*/
data-styled.g32[id="list__List-sc-s5kxp2-0"]{content:"clNcHj,"}/*!sc*/
.ckqxGA{z-index:0;}/*!sc*/
data-styled.g37[id="layout___StyledBox-sc-7a5ttt-0"]{content:"ckqxGA,"}/*!sc*/
.bQueYM{margin-bottom:10px;}/*!sc*/
.bQueYM:before{content:"\2022";color:#6a737d;display:inline-block;width:16px;margin-left:-16px;}/*!sc*/
data-styled.g38[id="reference-li__ReferenceLi-sc-1rtyfvw-0"]{content:"bQueYM,"}/*!sc*/
.cNqnCg{list-style:none;}/*!sc*/
data-styled.g39[id="table-of-contents___StyledBox-sc-1jtv948-0"]{content:"cNqnCg,"}/*!sc*/
.fgqKUG{grid-area:table-of-contents;overflow:auto;}/*!sc*/
data-styled.g40[id="post-page___StyledBox-sc-17hbw1s-0"]{content:"fgqKUG,"}/*!sc*/
</style><title data-react-helmet="true">Computer vision - Gatsby Theme Primer Wiki</title><meta data-react-helmet="true" name="description" content="Links OpenCV  - Open Source Computer Vision Library. ( Web ) ( OpenCV Course ) Gluon CV Toolkit  - Provides implementations…"/><meta data-react-helmet="true" name="image" content="https://user-images.githubusercontent.com/10384315/53922681-2f6d3100-402a-11e9-9719-5d1811c8110a.png"/><meta data-react-helmet="true" property="og:title" content="Computer vision"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:url" content="https://wiki.demo.owenyoung.com/computer-graphics/computer-vision/computer-vision/"/><meta data-react-helmet="true" property="og:image" content="https://user-images.githubusercontent.com/10384315/53922681-2f6d3100-402a-11e9-9719-5d1811c8110a.png"/><meta data-react-helmet="true" property="og:image:alt" content="A Gatsby theme for creating Primer wiki sites"/><meta data-react-helmet="true" property="og:site_name"/><meta data-react-helmet="true" property="og:description" content="Links OpenCV  - Open Source Computer Vision Library. ( Web ) ( OpenCV Course ) Gluon CV Toolkit  - Provides implementations…"/><meta data-react-helmet="true" property="article:published_time" content="2021-08-13T21:12:02.000Z"/><meta data-react-helmet="true" property="article:modified_time" content="2021-08-21T19:30:25.000Z"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="article:section" content="None"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:title" content="Computer vision"/><meta data-react-helmet="true" name="twitter:description" content="Links OpenCV  - Open Source Computer Vision Library. ( Web ) ( OpenCV Course ) Gluon CV Toolkit  - Provides implementations…"/><meta data-react-helmet="true" name="twitter:image" content="https://user-images.githubusercontent.com/10384315/53922681-2f6d3100-402a-11e9-9719-5d1811c8110a.png"/><meta data-react-helmet="true" name="twitter:image:alt" content="A Gatsby theme for creating Primer wiki sites"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="icon" href="/favicon-32x32.png?v=f3da5bc9ee21801506bcf83c84f79ae4" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=f3da5bc9ee21801506bcf83c84f79ae4"/><link as="script" rel="preload" href="/webpack-runtime-e630ae35d4e9aa0fd704.js"/><link as="script" rel="preload" href="/framework-1d3d9aa5e841da8133c8.js"/><link as="script" rel="preload" href="/bac1b955-c7037fb56cfc5cbde018.js"/><link as="script" rel="preload" href="/fba589a3-7e142401208b26326fdb.js"/><link as="script" rel="preload" href="/commons-d4c182a2050629043f01.js"/><link as="script" rel="preload" href="/app-cced7f1f6141af0d4cc8.js"/><link as="script" rel="preload" href="/component---theme-src-templates-post-query-js-4a3352054e86ce1ce39f.js"/><link as="fetch" rel="preload" href="/page-data/computer-graphics/computer-vision/computer-vision/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2220803758.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2320115945.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3495835395.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/451533639.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><a class="Link-sc-1brdqhf-0 hcoYYI skip-link__SkipLink-sc-1z0kjxc-0 fMyqIQ" color="auto.white" href="#skip-nav" font-size="1">Skip to content</a><div display="flex" color="text.primary" class="Box-nv15kw-0 hWMpfP"><div class="Box-nv15kw-0 etfTiI"><div display="flex" height="66" color="header.text" class="Box-nv15kw-0 gxBhQZ"><div display="flex" class="Box-nv15kw-0 bFIlIE"><a href="/" color="header.logo" class="Link-sc-1brdqhf-0 bhsmYh"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 ccmZUE" viewBox="0 0 16 16" width="32" height="32" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg></a><a color="header.logo" font-family="mono" class="Link-sc-1brdqhf-0 eUMSQB" href="/">Wiki</a><div display="none,,,block" class="Box-nv15kw-0 hWjVUJ"><div role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-search-label" class="Box-nv15kw-0 jyqrg"><span class="TextInput__Wrapper-sc-1apmpmt-1 eGxJgu dark-text-input__DarkTextInput-sc-1s2iwzn-0 cVQXPh TextInput-wrapper" width="240"><input type="text" aria-autocomplete="list" aria-labelledby="downshift-search-label" autoComplete="off" value="" id="downshift-search-input" placeholder="Search Wiki" class="TextInput__Input-sc-1apmpmt-0 iNJUGh"/></span></div></div></div><div display="flex" class="Box-nv15kw-0 sYKmk"><div display="none,,,flex" class="Box-nv15kw-0 cpSbMw"><div display="flex" color="header.text" class="Box-nv15kw-0 hRAPrM"><a href="https://github.com/theowenyoung/gatsby-theme-primer-wiki" display="block" color="inherit" class="Link-sc-1brdqhf-0 dNECOn">Github</a></div><button aria-label="Theme" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV dABgSo ghqbdb"><svg aria-hidden="true" role="img" class="octicon octicon-sun" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z"></path></svg></button></div><div display="flex,,,none" class="Box-nv15kw-0 ioFHus"><button aria-label="Search" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV gTTyEa ghqbdb"><svg aria-hidden="true" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z"></path></svg></button></div><button aria-label="Show Graph Visualisation" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV cBojNI ghqbdb"><div title="Show Graph Visualisation" aria-label="Show Graph Visualisation" color="header.text" display="flex" class="Box-nv15kw-0 bwociq"><svg t="1607341341241" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M512 512m-125.866667 0a125.866667 125.866667 0 1 0 251.733334 0 125.866667 125.866667 0 1 0-251.733334 0Z"></path><path d="M512 251.733333m-72.533333 0a72.533333 72.533333 0 1 0 145.066666 0 72.533333 72.533333 0 1 0-145.066666 0Z"></path><path d="M614.4 238.933333c0 4.266667 2.133333 8.533333 2.133333 12.8 0 19.2-4.266667 36.266667-12.8 51.2 81.066667 36.266667 138.666667 117.333333 138.666667 211.2C742.4 640 640 744.533333 512 744.533333s-230.4-106.666667-230.4-232.533333c0-93.866667 57.6-174.933333 138.666667-211.2-8.533333-14.933333-12.8-32-12.8-51.2 0-4.266667 0-8.533333 2.133333-12.8-110.933333 42.666667-189.866667 147.2-189.866667 273.066667 0 160 130.133333 292.266667 292.266667 292.266666S804.266667 672 804.266667 512c0-123.733333-78.933333-230.4-189.866667-273.066667z"></path><path d="M168.533333 785.066667m-72.533333 0a72.533333 72.533333 0 1 0 145.066667 0 72.533333 72.533333 0 1 0-145.066667 0Z"></path><path d="M896 712.533333m-61.866667 0a61.866667 61.866667 0 1 0 123.733334 0 61.866667 61.866667 0 1 0-123.733334 0Z"></path><path d="M825.6 772.266667c-74.666667 89.6-187.733333 147.2-313.6 147.2-93.866667 0-181.333333-32-249.6-87.466667-10.666667 19.2-25.6 34.133333-44.8 44.8C298.666667 942.933333 401.066667 981.333333 512 981.333333c149.333333 0 281.6-70.4 366.933333-177.066666-21.333333-4.266667-40.533333-17.066667-53.333333-32zM142.933333 684.8c-25.6-53.333333-38.4-110.933333-38.4-172.8C104.533333 288 288 104.533333 512 104.533333S919.466667 288 919.466667 512c0 36.266667-6.4 72.533333-14.933334 106.666667 23.466667 2.133333 42.666667 10.666667 57.6 25.6 12.8-42.666667 19.2-87.466667 19.2-132.266667 0-258.133333-211.2-469.333333-469.333333-469.333333S42.666667 253.866667 42.666667 512c0 74.666667 17.066667 142.933333 46.933333 204.8 14.933333-14.933333 32-27.733333 53.333333-32z"></path></svg><span display="none,,,inline" class="Text-sc-1s3uzov-0 gkRvDD">Show Graph Visualisation</span></div></button><div display="flex,,,none" class="Box-nv15kw-0 ioFHus"><button aria-label="Menu" aria-expanded="false" class="ButtonBase-sc-181ps9o-0 ButtonOutline-sc-15gta9l-0 dark-button__DarkButton-sc-bvvmfe-0 kNqLJV dABgSo ghqbdb"><svg aria-hidden="true" role="img" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path></svg></button></div></div></div></div><div display="flex" class="Box-nv15kw-0 layout___StyledBox-sc-7a5ttt-0 dkAYKh ckqxGA"><div display="none,,,block" height="calc(100vh - 66px)" color="auto.gray.8" class="Box-nv15kw-0 jJoPUf"><div height="100%" style="overflow:auto" class="Box-nv15kw-0 bofEBa"><div display="flex" class="Box-nv15kw-0 erCMck"><div class="Box-nv15kw-0 gqMphN"><div display="flex" class="Box-nv15kw-0 erCMck"><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><div color="text.secondary" font-weight="400" class="Box-nv15kw-0 nav-items__NavBox-sc-tqz5wl-1 cWWGJy lcMKXT" display="block">Meta</div><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/sharing/sharing/">Sharing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/ideas/ideas/">Ideas</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/focusing/focusing/">Focusing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/minimalism/minimalism/">Minimalism</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/research/research/">Research</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/knowledge/knowledge/">Knowledge</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/environment/environment/">Environment</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/music/music/">Music</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/life/life/">Life</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/writing/writing/">Writing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/macOS/macOS/">macOS</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/hardware/hardware/">Hardware</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/math/math/">Math</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/computer-science/computer-science/">Computer Science</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/programming/programming/">Programming</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/programming-languages/programming-languages/">Programming languages</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/data-science/data-science/">Data Science</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/open-source/open-source/">Open Source</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/languages/languages/">Languages</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/text-editors/text-editors/">Text editors</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/operating-systems/operating-systems/">Operating systems</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/package-managers/package-managers/">Package managers</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/devops/devops/">DevOps</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/mindfulness/mindfulness/">Mindfulness</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/compilers/compilers/">Compilers</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/physics/physics/">Physics</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/biology/biology/">Biology</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/automation/automation/">Automation</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/education/education/">Education</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/economy/economy/">Economy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/governance/governance/">Governance</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/consciousness/consciousness/">Consciousness</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/drugs/drugs/">Drugs</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/chemistry/chemistry/">Chemistry</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/unix/unix/">Unix</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/web/web/">Web</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/cloud-computing/cloud-computing/">Cloud computing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/front-end/front-end/">Front End</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/security/security/">Security</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/social-networks/social-networks/">Social networks</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/networking/networking/">Networking</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/health/health/">Health</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/fitness/fitness/">Fitness</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/medicine/medicine/">Medicine</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/history/history/">History</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/travel/travel/">Travel</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/geography/geography/">Geography</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/business/business/">Business</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/relationships/relationships/">Relationships</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/3d-printing/3d-printing/">3D Printing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/anki/anki/">Anki</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/philosophy/philosophy/">Philosophy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/video/video/">Video</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/machine-learning/machine-learning/">Machine learning</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/computer-graphics/">Computer graphics</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/image-processing/">Image processing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a aria-current="page" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD active" display="block" sx="[object Object]" href="/computer-graphics/computer-vision/computer-vision/">Computer vision</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-up" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M3.22 9.78a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 0l4.25 4.25a.75.75 0 01-1.06 1.06L8 6.06 4.28 9.78a.75.75 0 01-1.06 0z"></path></svg></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/computer-vision/ocr/">OCR</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/procedural-generation/">Procedural generation</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/rendering/">Rendering</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/shaders/">Shaders</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/ray-tracing/">Ray Tracing</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/bezier-curves/">Bezier curves</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/cuda/">CUDA</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/webgpu/">WebGPU</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/webgl/">WebGL</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/metal/">Metal</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/vulkan/">Vulkan</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/opengl/">OpenGL</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 bicbnc"><div display="flex" font-size="1" class="Box-nv15kw-0 hsHDpf"><a class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 iBmcyt fgkVQD" display="block" sx="[object Object]" href="/computer-graphics/svg/">SVG</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/tools/tools/">Tools</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/design/design/">Design</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/keyboards/keyboards/">Keyboards</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/future/future/">Future</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/cryptocurrencies/cryptocurrencies/">Cryptocurrencies</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/privacy/privacy/">Privacy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/games/games/">Games</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/streaming/streaming/">Streaming</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/talks/talks/">Talks</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/analytics/analytics/">Analytics</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/databases/databases/">Databases</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/art/art/">Art</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/api/api/">API</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/distributed-systems/distributed-systems/">Distributed systems</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/backups/backups/">Backups</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/space/space/">Space</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/psychology/psychology/">Psychology</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/sleep/sleep/">Sleep</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/irc/irc/">IRC</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/work/work/">Work</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/management/management/">Management</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/latex/latex/">LaTeX</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/robots/robots/">Robots</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/nlp/nlp/">NLP</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/virtual-reality/virtual-reality/">Virtual Reality</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/augmented-reality/augmented-reality/">Augmented Reality</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/neuroscience/neuroscience/">Neuroscience</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/cli/cli/">CLI</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/humans/humans/">Humans</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/philanthropy/philanthropy/">Philanthropy</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/animals/animals/">Animals</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/podcasts/podcasts/">Podcasts</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/documentaries/documentaries/">Documentaries</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/movies/movies/">Movies</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/tv-series/tv-series/">TV series</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/courses/courses/">Courses</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/articles/articles/">Articles</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/poems/poems/">Poems</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/research-papers/research-papers/">Research papers</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/books/books/">Books</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/other/other/">Other</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/notes/notes/">Notes</a><div display="flex" class="Box-nv15kw-0 bCkTHX"></div></div></div><div display="flex" class="Box-nv15kw-0 gfcHFT"><div display="flex" font-size="1" class="Box-nv15kw-0 kanhPD"><a color="text.primary" class="Link-sc-1brdqhf-0 nav-items__NavLink-sc-tqz5wl-0 hNrChk fgkVQD" display="block" sx="[object Object]" href="/looking-back/looking-back/">Looking back</a><div display="flex" class="Box-nv15kw-0 bCkTHX"><svg aria-hidden="true" role="img" class="octicon octicon-chevron-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M12.78 6.22a.75.75 0 010 1.06l-4.25 4.25a.75.75 0 01-1.06 0L3.22 7.28a.75.75 0 011.06-1.06L8 9.94l3.72-3.72a.75.75 0 011.06 0z"></path></svg></div></div></div></div></div></div></div></div><main class="Box-nv15kw-0 YYpGb"><div id="skip-nav" display="flex" width="100%" class="Box-nv15kw-0 jcXqAE"><div display="none,,block" class="Box-nv15kw-0 post-page___StyledBox-sc-17hbw1s-0 fWFLOe fgqKUG"><span display="inline-block" font-weight="bold" class="Text-sc-1s3uzov-0 behEry">On this page</span><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 kJfdyq"><a display="inline-block" href="#computer-vision" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Computer vision</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 eqzAwh"><a display="inline-block" href="#links" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Links</a></li></ul></li></ul></div><div width="100%" class="Box-nv15kw-0 ejaYSC"><div display="block,,none" class="Box-nv15kw-0 bZmuzz"><div class="Box-nv15kw-0 hdoRyz"><div display="flex" class="Box-nv15kw-0 ePSgtU"><span font-weight="bold" class="Text-sc-1s3uzov-0 ebhDkJ">On this page</span></div></div><div class="Box-nv15kw-0 fiEpCu"><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 kJfdyq"><a display="inline-block" href="#computer-vision" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Computer vision</a><ul class="Box-nv15kw-0 table-of-contents___StyledBox-sc-1jtv948-0 dNoCtD cNqnCg"><li class="Box-nv15kw-0 eqzAwh"><a display="inline-block" href="#links" font-size="2,,1" color="auto.gray.6" class="Link-sc-1brdqhf-0 draiCu">Links</a></li></ul></li></ul></div></div><h1 id="computer-vision" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH1-sc-1fu06k9-1 cRbSBD jojuSi iEQqUA Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 cRbSBD jojuSi"><a href="#computer-vision" color="auto.gray.8" aria-label="Computer vision permalink" class="Link-sc-1brdqhf-0 kydbMn"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computer vision</h1><h2 id="links" class="Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 heading__StyledH2-sc-1fu06k9-2 cRbSBD jojuSi kLBshj Heading-sc-1cjoo9h-0 heading__StyledHeading-sc-1fu06k9-0 cRbSBD jojuSi"><a href="#links" color="auto.gray.8" aria-label="Links permalink" class="Link-sc-1brdqhf-0 kydbMn"><svg aria-hidden="true" role="img" class="octicon-link" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Links</h2><ul class="list__List-sc-s5kxp2-0 clNcHj"><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/opencv/opencv" class="Link-sc-1brdqhf-0 fWewSX">OpenCV</a> - Open Source Computer Vision Library. (<a target="_blank" rel="noopener noreferrer" href="https://opencv.org/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>) (<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=oXlwWbU8l2o" class="Link-sc-1brdqhf-0 fWewSX">OpenCV Course</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dmlc/gluon-cv" class="Link-sc-1brdqhf-0 fWewSX">Gluon CV Toolkit</a> - Provides implementations of the sate-of-the-art (SOTA) deep learning models in computer vision.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/pythia" class="Link-sc-1brdqhf-0 fWewSX">Pythia</a> - Modular framework for vision and language multimodal research. Built on top of PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/zllrunning/video-object-removal" class="Link-sc-1brdqhf-0 fWewSX">video-object-removal</a> - Just draw a bounding box and you can remove the object you want to remove.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hybridgroup/gocv" class="Link-sc-1brdqhf-0 fWewSX">GoCV</a> - Go package for computer vision using OpenCV 4 and beyond.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/osmr/imgclsmob" class="Link-sc-1brdqhf-0 fWewSX">Sandbox for training convolutional networks for computer vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.pyimagesearch.com/start-here/" class="Link-sc-1brdqhf-0 fWewSX">Get started with Computer Vision, Deep Learning, and OpenCV</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/donnyyou/torchcv" class="Link-sc-1brdqhf-0 fWewSX">TorchCV</a> - PyTorch-Based Framework for Deep Learning in Computer Vision.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/habitat-sim" class="Link-sc-1brdqhf-0 fWewSX">AI Habitat</a> - Flexible, high-performance 3D simulator for Embodied AI research.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kornia/kornia" class="Link-sc-1brdqhf-0 fWewSX">Kornia</a> - Open Source Differentiable Computer Vision Library for PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://roboflow.com/" class="Link-sc-1brdqhf-0 fWewSX">Roboflow</a> - Raw images to trained computer vision model. (<a target="_blank" rel="noopener noreferrer" href="https://nickarner.com/notes/roboflow-memo-february-1-2021/" class="Link-sc-1brdqhf-0 fWewSX">Article</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/SlowFast" class="Link-sc-1brdqhf-0 fWewSX">PySlowFast</a> - Open source video understanding codebase from FAIR that provides state-of-the-art video classification models.</li><li><a target="_blank" rel="noopener noreferrer" href="https://brohrer.github.io/images_to_numbers.html" class="Link-sc-1brdqhf-0 fWewSX">How to Convert a Picture to Numbers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision" class="Link-sc-1brdqhf-0 fWewSX">Awesome Computer Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p" class="Link-sc-1brdqhf-0 fWewSX">The Ancient Secrets of Computer Vision (2018)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=fpw26tpHGr8&amp;list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI" class="Link-sc-1brdqhf-0 fWewSX">Variational Methods for Computer Vision lectures (2013)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/ClassyVision" class="Link-sc-1brdqhf-0 fWewSX">Classy Vision</a> - New end-to-end, PyTorch-based framework for large-scale training of state-of-the-art image and video classification models.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/alicevision/meshroom" class="Link-sc-1brdqhf-0 fWewSX">Meshroom</a> - 3D Reconstruction Software.</li><li><a target="_blank" rel="noopener noreferrer" href="https://alicevision.org/" class="Link-sc-1brdqhf-0 fWewSX">AliceVision</a> - Photogrammetric Computer Vision Framework. (<a target="_blank" rel="noopener noreferrer" href="https://github.com/alicevision/AliceVision" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/alicevision" class="Link-sc-1brdqhf-0 fWewSX">GitHub</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/pytorch3d" class="Link-sc-1brdqhf-0 fWewSX">PyTorch3d</a> - Provides efficient, reusable components for 3D Computer Vision research with PyTorch. (<a target="_blank" rel="noopener noreferrer" href="https://pytorch3d.org/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ageitgey/face_recognition" class="Link-sc-1brdqhf-0 fWewSX">Face Recognition</a> - World&#x27;s simplest facial recognition api for Python and the command line.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/votenet" class="Link-sc-1brdqhf-0 fWewSX">Deep Hough Voting for 3D Object Detection in Point Clouds</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/PointCloudLibrary/pcl" class="Link-sc-1brdqhf-0 fWewSX">Point Cloud Library</a> - Standalone, large scale, open project for 2D/3D image and point cloud processing.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jasonmayes/Real-Time-Person-Removal" class="Link-sc-1brdqhf-0 fWewSX">Disappearing-People</a> - Removing people from complex backgrounds in real time using TensorFlow.js in the web browser. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22353596" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/computervision-recipes" class="Link-sc-1brdqhf-0 fWewSX">Best Practices, code samples, and documentation for Computer Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/amzn/computer-vision-basics-in-microsoft-excel" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision Basics in Microsoft Excel</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2002.10880" class="Link-sc-1brdqhf-0 fWewSX">PolyGen: An Autoregressive Generative Model of 3D Meshes (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/strasdat/Sophus" class="Link-sc-1brdqhf-0 fWewSX">Sophus</a> - C++ implementation of Lie Groups using Eigen.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/MIPT-Oulu/solt" class="Link-sc-1brdqhf-0 fWewSX">SOLT</a> - Streaming over lightweight data transformations.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jiachenli94/Awesome-Interaction-aware-Trajectory-Prediction" class="Link-sc-1brdqhf-0 fWewSX">Awesome Interaction-aware Behavior and Trajectory Prediction</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.robots.ox.ac.uk/~ow/synsin.html" class="Link-sc-1brdqhf-0 fWewSX">SynSin: End-to-end View Synthesis from a Single Image (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/synsin" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/nywang16/Pixel2Mesh" class="Link-sc-1brdqhf-0 fWewSX">Pixel2Mesh</a> - Generating 3D Mesh Models from Single RGB Images.</li><li><a target="_blank" rel="noopener noreferrer" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" class="Link-sc-1brdqhf-0 fWewSX">First Order Motion Model for Image Animation</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/AliaksandrSiarohin/first-order-model" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/cleardusk/3DDFA" class="Link-sc-1brdqhf-0 fWewSX">PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex04072000/ObstructionRemoval" class="Link-sc-1brdqhf-0 fWewSX">Learning to See Through Obstructions</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yl-1993/learn-to-cluster" class="Link-sc-1brdqhf-0 fWewSX">Learning to Cluster Faces on an Affinity Graph (LTC)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/alievk/avatarify" class="Link-sc-1brdqhf-0 fWewSX">Avatarify</a> - Avatars for Zoom and Skype.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Maclory/SPSR" class="Link-sc-1brdqhf-0 fWewSX">SPSR</a> - PyTorch implementation of Structure-Preserving Super Resolution with Gradient Guidance.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/HolmesShuan/OISR-PyTorch" class="Link-sc-1brdqhf-0 fWewSX">OISR-PyTorch</a> - PyTorch implementation of &quot;ODE-inspired Network Design for Single Image Super-Resolution.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vt-vl-lab/3d-photo-inpainting" class="Link-sc-1brdqhf-0 fWewSX">3D Photography using Context-aware Layered Depth Inpainting</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/youngwanLEE/CenterMask" class="Link-sc-1brdqhf-0 fWewSX">CenterMask : Real-Time Anchor-Free Instance Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=lWwkbiufwNE" class="Link-sc-1brdqhf-0 fWewSX">Interview with Dmytro Mushkin | Computer Vision Research | Kaggle, ML &amp; Education (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/devendrachaplot/Neural-SLAM" class="Link-sc-1brdqhf-0 fWewSX">Pytorch code for ICLR-20 Paper &quot;Learning to Explore using Active Neural SLAM&quot;</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kylemcdonald/FaceTracker" class="Link-sc-1brdqhf-0 fWewSX">FaceTracker</a> - Real time deformable face tracking in C++ with OpenCV 3.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ChaofWang/Awesome-Super-Resolution" class="Link-sc-1brdqhf-0 fWewSX">Awesome Super Resolution</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/podgorskiy/ALAE" class="Link-sc-1brdqhf-0 fWewSX">Adversarial Latent Autoencoders</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mp3guy/ElasticFusion" class="Link-sc-1brdqhf-0 fWewSX">ElasticFusion</a> - Real-time dense visual SLAM system capable of capturing comprehensive dense globally consistent surfel-based maps of room scale environments explored using an RGB-D camera.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tancik/StegaStamp" class="Link-sc-1brdqhf-0 fWewSX">StegaStamp: Invisible Hyperlinks in Physical Photographs</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yemount/pose-animator/" class="Link-sc-1brdqhf-0 fWewSX">Pose Animator</a> - Takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23124786" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/fvcore" class="Link-sc-1brdqhf-0 fWewSX">fvcore</a> - Collection of common code that&#x27;s shared among different research projects in FAIR computer vision team.</li><li><a target="_blank" rel="noopener noreferrer" href="http://ai.stanford.edu/blog/selfsupervised-multimodal/" class="Link-sc-1brdqhf-0 fWewSX">Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/cyrildiagne/screenpoint" class="Link-sc-1brdqhf-0 fWewSX">ScreenPoint</a> - Project an image centroid to another image using OpenCV.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/NathanUA/U-2-Net" class="Link-sc-1brdqhf-0 fWewSX">U^2-Net</a> - Code for our newly accepted paper in Pattern Recognition 2020: &quot;U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection&quot;.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/fepegar/torchio" class="Link-sc-1brdqhf-0 fWewSX">TorchIO</a> - Tools for medical image processing in deep learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/anandpawara/Real_Time_Image_Animation" class="Link-sc-1brdqhf-0 fWewSX">Real time Image Animation in OpenCV using first order model</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23312259" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openmv/openmv" class="Link-sc-1brdqhf-0 fWewSX">OpenMV (Open-Source Machine Vision)</a> - Aims at making machine vision more accessible to beginners by developing a user-friendly, open-source, low-cost machine vision platform.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Sense-X/TSD" class="Link-sc-1brdqhf-0 fWewSX">TSD</a> - 1st place models in Google OpenImage Detection Challenge 2019.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ZJULearning/ttfnet" class="Link-sc-1brdqhf-0 fWewSX">Training-Time-Friendly Network for Real-Time Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/google-research/big_transfer" class="Link-sc-1brdqhf-0 fWewSX">Big Transfer (BiT): General Visual Representation Learning</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ilovepose/fast-human-pose-estimation.pytorch" class="Link-sc-1brdqhf-0 fWewSX">Fast Human Pose Estimation CVPR2019</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/leoxiaobin/deep-high-resolution-net.pytorch" class="Link-sc-1brdqhf-0 fWewSX">Deep High-Resolution Representation Learning for Human Pose Estimation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/senguptaumd/Background-Matting" class="Link-sc-1brdqhf-0 fWewSX">Background Matting: The World is Your Green Screen</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/detr" class="Link-sc-1brdqhf-0 fWewSX">DE⫶TR: End-to-End Object Detection with Transformers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/shunsukesaito/PIFu" class="Link-sc-1brdqhf-0 fWewSX">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/xingyizhou/CenterTrack" class="Link-sc-1brdqhf-0 fWewSX">Tracking Objects as Points</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mkocabas/VIBE" class="Link-sc-1brdqhf-0 fWewSX">VIBE</a> - Video Inference for Human Body Pose and Shape Estimation.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/idearibosome/srzoo" class="Link-sc-1brdqhf-0 fWewSX">SRZoo</a> - Integrated repository for super-resolution using deep learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Cartucho/mAP" class="Link-sc-1brdqhf-0 fWewSX">mAP (mean Average Precision)</a> - Evaluates the performance of your neural net for object recognition.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jiashunwang/Neural-Pose-Transfer" class="Link-sc-1brdqhf-0 fWewSX">Neural Pose Transfer by Spatially Adaptive Instance Normalization (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/weihaox/awesome-neural-rendering" class="Link-sc-1brdqhf-0 fWewSX">Awesome Neural Rendering</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wvangansbeke/Unsupervised-Classification" class="Link-sc-1brdqhf-0 fWewSX">Learning To Classify Images Without Labels</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mit-han-lab/dlg" class="Link-sc-1brdqhf-0 fWewSX">Deep Leakage From Gradients (2019)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.3dflow.net/" class="Link-sc-1brdqhf-0 fWewSX">3Dflow</a> - Offers customized computer vision software solutions.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wkentaro/labelme" class="Link-sc-1brdqhf-0 fWewSX">labelme</a> - Image Polygonal Annotation with Python.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wkentaro/imgviz" class="Link-sc-1brdqhf-0 fWewSX">imgviz</a> - Image Visualization Tools.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wukaoliu/CVPR2020-HAttMatting" class="Link-sc-1brdqhf-0 fWewSX">Attention-Guided Hierarchical Structure Aggregation for Image Matting</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.roboflow.ai/yolov5-is-here/" class="Link-sc-1brdqhf-0 fWewSX">YOLOv5 Is Here: State-of-the-Art Object Detection at 140 FPS (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23478151" class="Link-sc-1brdqhf-0 fWewSX">HN</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ultralytics/yolov5" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/joe-siyuan-qiao/DetectoRS" class="Link-sc-1brdqhf-0 fWewSX">DetectoRS</a> - Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/thepowerfuldeez/facemesh.pytorch" class="Link-sc-1brdqhf-0 fWewSX">PyTorch implementation of paper Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kdexd/virtex" class="Link-sc-1brdqhf-0 fWewSX">VirTex: Learning Visual Representations from Textual Annotations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/pifuhd" class="Link-sc-1brdqhf-0 fWewSX">High-Resolution 3D Human Digitization from A Single Image</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ifzhang/FairMOT" class="Link-sc-1brdqhf-0 fWewSX">FairMOT</a> - Simple baseline for one-shot multi-object tracking.</li><li><a target="_blank" rel="noopener noreferrer" href="https://vsitzmann.github.io/siren/" class="Link-sc-1brdqhf-0 fWewSX">Implicit Neural Representations with Periodic Activation Functions (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mseg-dataset/mseg-semantic" class="Link-sc-1brdqhf-0 fWewSX">MSeg: A Composite Dataset for Multi-Domain Segmentation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/CuriousAI/mean-teacher" class="Link-sc-1brdqhf-0 fWewSX">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/open-mmlab/mmdetection" class="Link-sc-1brdqhf-0 fWewSX">MMDetection</a> - OpenMMLab Detection Toolbox and Benchmark.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/noahtren/Fourier-Feature-Networks-TensorFlow-2" class="Link-sc-1brdqhf-0 fWewSX">Fourier Feature Networks in TensorFlow 2</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://vision.ee.ethz.ch/" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision Lab | ETH Zurich</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5" class="Link-sc-1brdqhf-0 fWewSX">PyTorch Computer Vision Library for Experts and Beginners (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/balavenkatesh3322/CV-pretrained-model" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision Pretrained Models</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://sandlab.cs.uchicago.edu/fawkes/" class="Link-sc-1brdqhf-0 fWewSX">Fawkes: Image “Cloaking” for Personal Privacy</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23917337" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Motion-Project/motion" class="Link-sc-1brdqhf-0 fWewSX">Motion</a> - Software motion detector.</li><li><a target="_blank" rel="noopener noreferrer" href="https://nextjournal.com/nirmal-suthar/supervised-3d-mesh-reconstruction" class="Link-sc-1brdqhf-0 fWewSX">Supervised 3D Mesh Reconstruction (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://nerf-w.github.io/" class="Link-sc-1brdqhf-0 fWewSX">NeRF in the Wild</a> - Neural Radiance Fields for Unconstrained Photo Collections.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1912.03207" class="Link-sc-1brdqhf-0 fWewSX">NASA: Neural Articulated Shape Approximation (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2008.06365v2" class="Link-sc-1brdqhf-0 fWewSX">An Overview of Deep Learning Architectures in Few-Shot Learning Domain (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1803.11288" class="Link-sc-1brdqhf-0 fWewSX">FutureMapping: The Computational Structure of Spatial AI Systems (2018)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/AjdDavison/status/1045617261925543937" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/" class="Link-sc-1brdqhf-0 fWewSX">Optimal Peanut Butter and Banana Sandwiches (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/eprosenthal/status/1298290961294950401" class="Link-sc-1brdqhf-0 fWewSX">Twitter</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://justinmeiners.github.io/gesture-recognition/" class="Link-sc-1brdqhf-0 fWewSX">Gesture Recognition with Line Integrals</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/justinmeiners/gesture-recognition" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://slazebni.cs.illinois.edu/spring20/" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision: Looking Back to Look Forward (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/baowenbo/DAIN" class="Link-sc-1brdqhf-0 fWewSX">DAIN (Depth-Aware Video Frame Interpolation)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://picsellia.com/" class="Link-sc-1brdqhf-0 fWewSX">Picsellia</a> - Development platform dedicated to Computer Vision.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vita-epfl/openpifpaf" class="Link-sc-1brdqhf-0 fWewSX">Official implementation of &quot;PifPaf: Composite Fields for Human Pose Estimation&quot; in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://link.springer.com/chapter/10.1007/3-540-46805-6_19" class="Link-sc-1brdqhf-0 fWewSX">Object Recognition with Gradient-Based Learning (1999)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/NVlabs/imaginaire" class="Link-sc-1brdqhf-0 fWewSX">Imaginaire</a> - NVIDIA PyTorch GAN library with distributed and mixed precision support. (<a target="_blank" rel="noopener noreferrer" href="http://imaginaire.cc/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/floe/deepbacksub" class="Link-sc-1brdqhf-0 fWewSX">DeepBackSub</a> - Virtual Video Device for Background Replacement with Deep Semantic Segmentation.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kuanhungchen/awesome-tiny-object-detection" class="Link-sc-1brdqhf-0 fWewSX">Awesome Tiny Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vt-vl-lab/FGVC" class="Link-sc-1brdqhf-0 fWewSX">Flow-edge Guided Video Completion</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/" class="Link-sc-1brdqhf-0 fWewSX">5 Things to look for in a Computer Vision startup job (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=Gl48KciWZp0" class="Link-sc-1brdqhf-0 fWewSX">Transformers for Image Recognition at Scale (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24754538" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/MIC-DKFZ/nnUNet" class="Link-sc-1brdqhf-0 fWewSX">nnU-Net</a> - Segmentation method that is designed to deal with the dataset diversity.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/MIC-DKFZ/batchgenerators" class="Link-sc-1brdqhf-0 fWewSX">batchgenerators</a> - Framework for data augmentation for 2D and 3D image classification and segmentation.</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.lookuq.com/create-your-own-app" class="Link-sc-1brdqhf-0 fWewSX">Lookuq</a> - App to create object detection projects without coding. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24784680" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepinsight/insightface" class="Link-sc-1brdqhf-0 fWewSX">InsightFace</a> - Face Analysis Project on MXNet. (<a target="_blank" rel="noopener noreferrer" href="http://insightface.ai/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/swav" class="Link-sc-1brdqhf-0 fWewSX">PyTorch implementation of SwAV (Swapping Assignments between Views)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Alibaba-MIIL/ASL" class="Link-sc-1brdqhf-0 fWewSX">Asymmetric Loss For Multi-Label Classification in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/adobe/antialiased-cnns" class="Link-sc-1brdqhf-0 fWewSX">Antialiased CNNs</a> - Making Convolutional Networks Shift-Invariant Again.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/richzhang/PerceptualSimilarity" class="Link-sc-1brdqhf-0 fWewSX">Perceptual Similarity Metric and Dataset</a> - Unreasonable Effectiveness of Deep Features as a Perceptual Metric.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/deeppomf/DeepLearningAnimePapers" class="Link-sc-1brdqhf-0 fWewSX">Deep Learning Anime Papers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/google-research/vision_transformer" class="Link-sc-1brdqhf-0 fWewSX">Vision Transformer</a> - Models from the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/MIDIBlocks/handsfree" class="Link-sc-1brdqhf-0 fWewSX">Handsfree.js</a> - Wrapper library around computer vision models for working with face pointers, assistive tech, and creative expression. (<a target="_blank" rel="noopener noreferrer" href="https://handsfreejs.glitch.me/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/amirgholami/ZeroQ" class="Link-sc-1brdqhf-0 fWewSX">ZeroQ: A Novel Zero Shot Quantization Framework</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/amirgholami/SqueezeNext" class="Link-sc-1brdqhf-0 fWewSX">SqueezeNext</a> - Contains the Caffe implementation of SqueezeNext.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/amirgholami/anode" class="Link-sc-1brdqhf-0 fWewSX">ANODE: Adjoint Based Neural ODEs</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/AdamSpannbauer/python_video_stab" class="Link-sc-1brdqhf-0 fWewSX">Python Video Stabilization using OpenCV</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers" class="Link-sc-1brdqhf-0 fWewSX">Recent Advances in Vision and Language PreTrained Models (VL-PTMs)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kuangliu/torchcv" class="Link-sc-1brdqhf-0 fWewSX">TorchCV</a> - PyTorch vision library mimics ChainerCV.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jeonsworld/ViT-pytorch" class="Link-sc-1brdqhf-0 fWewSX">Vision Transformer in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/perone/medicaltorch" class="Link-sc-1brdqhf-0 fWewSX">MedicalTorch</a> - Medical imaging framework for PyTorch. (<a target="_blank" rel="noopener noreferrer" href="https://medicaltorch.readthedocs.io/en/stable/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/elcorto/imagecluster" class="Link-sc-1brdqhf-0 fWewSX">imagecluster</a> - Cluster images based on image content using a pre-trained deep neural network, optional time distance scaling and hierarchical clustering.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/alankbi/detecto" class="Link-sc-1brdqhf-0 fWewSX">Detecto</a> - Build fully-functioning computer vision models with PyTorch. (<a target="_blank" rel="noopener noreferrer" href="https://detecto.readthedocs.io/en/latest/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/thoughtworksarts/EmoPy" class="Link-sc-1brdqhf-0 fWewSX">EmoPy</a> - Deep neural net toolkit for emotion analysis via Facial Expression Recognition (FER).</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/NVlabs/NVAE" class="Link-sc-1brdqhf-0 fWewSX">PyTorch Implementation of &quot;NVAE: A Deep Hierarchical Variational Autoencoder&quot;</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/weijun88/LDF" class="Link-sc-1brdqhf-0 fWewSX">Label Decoupling Framework for Salient Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Project-MONAI/MONAI" class="Link-sc-1brdqhf-0 fWewSX">MONAI</a> - PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. (<a target="_blank" rel="noopener noreferrer" href="https://monai.io/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/implus/GFocal" class="Link-sc-1brdqhf-0 fWewSX">Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.paperspace.com/faster-r-cnn-explained-object-detection/" class="Link-sc-1brdqhf-0 fWewSX">Faster R-CNN Explained for Object Detection Tasks (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.jeremymorgan.com/tutorials/raspberry-pi/how-to-install-opencv-raspberry-pi/" class="Link-sc-1brdqhf-0 fWewSX">How to Install OpenCV on a Raspberry Pi (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/alexanderkroner/saliency" class="Link-sc-1brdqhf-0 fWewSX">Contextual Encoder-Decoder Network for Visual Saliency Prediction</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.pyimagesearch.com/" class="Link-sc-1brdqhf-0 fWewSX">PyImageSearch</a> - Master Computer Vision, Deep Learning, and OpenCV.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/hendrycks/natural-adv-examples" class="Link-sc-1brdqhf-0 fWewSX">Natural Adversarial Examples</a> - Harder ImageNet Test Set.</li><li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@venkateshpnk22/how-to-upload-50-opencv-frames-into-cloud-storage-within-1-second-653ee73d7711" class="Link-sc-1brdqhf-0 fWewSX">How to upload 50 OpenCV frames into cloud storage within 1 second (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://gvv.mpi-inf.mpg.de/projects/EgoChat/" class="Link-sc-1brdqhf-0 fWewSX">Egocentric Videoconferencing (2020)</a> - Method for egocentric videoconferencing that enables handsfree video calls, for instance by people wearing smart glasses or other mixedreality devices. (<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=atzPvW95ahQ" class="Link-sc-1brdqhf-0 fWewSX">Video overview</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/gradslam/gradslam" class="Link-sc-1brdqhf-0 fWewSX">gradslam</a> - Open source differentiable dense SLAM library for PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/saic-mdal/HiDT" class="Link-sc-1brdqhf-0 fWewSX">High-Resolution Daytime Translation Without Domain Labels</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/s9xie/hed" class="Link-sc-1brdqhf-0 fWewSX">Holistically-Nested Edge Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/pycls" class="Link-sc-1brdqhf-0 fWewSX">pycls</a> - Image classification codebase, written in PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Justin-Tan/high-fidelity-generative-compression" class="Link-sc-1brdqhf-0 fWewSX">PyTorch implementation of High-Fidelity Generative Image Compression + Routines for neural image compression</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/princeton-vl/selfstudy" class="Link-sc-1brdqhf-0 fWewSX">How Useful is Self-Supervised Pretraining for Visual Tasks?</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/adamian98/pulse" class="Link-sc-1brdqhf-0 fWewSX">PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/InterHand2.6M" class="Link-sc-1brdqhf-0 fWewSX">InterHand2.6M: A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/adipandas/multi-object-tracker" class="Link-sc-1brdqhf-0 fWewSX">Multi-object trackers in Python</a> - Easy to use implementation of various multi-object tracking algorithms.</li><li><a target="_blank" rel="noopener noreferrer" href="http://svl.stanford.edu/" class="Link-sc-1brdqhf-0 fWewSX">Stanford Vision and Learning Lab</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/StanfordVL" class="Link-sc-1brdqhf-0 fWewSX">GitHub</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://towardsdatascience.com/learning-computer-vision-41398ad9941f" class="Link-sc-1brdqhf-0 fWewSX">Learning computer vision. Overview of methods and software (2018)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@rom1504/image-embeddings-ed1b194d113e" class="Link-sc-1brdqhf-0 fWewSX">Image embeddings. Image similarity and building (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/rom1504/image_embeddings" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/" class="Link-sc-1brdqhf-0 fWewSX">All You Need to Know About Object Detection Systems (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/lightly-ai/lightly" class="Link-sc-1brdqhf-0 fWewSX">Lightly</a> - Computer vision framework for self-supervised learning.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2006.13566" class="Link-sc-1brdqhf-0 fWewSX">DISK: Learning local features with policy gradient (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/cvlab-epfl/disk" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jasmcaus/caer" class="Link-sc-1brdqhf-0 fWewSX">Caer</a> - Lightweight Computer Vision library for high-performance AI research. (<a target="_blank" rel="noopener noreferrer" href="https://towardsdatascience.com/introducing-caer-modern-computer-vision-on-the-fly-1619d7155c15" class="Link-sc-1brdqhf-0 fWewSX">Intro</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/weihaox/awesome-image-translation" class="Link-sc-1brdqhf-0 fWewSX">Awesome Image to Image Translation Papers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/toandaominh1997/EfficientDet.Pytorch" class="Link-sc-1brdqhf-0 fWewSX">EfficientDet: Scalable and Efficient Object Detection, in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/milesial/Pytorch-UNet" class="Link-sc-1brdqhf-0 fWewSX">UNet: semantic segmentation with PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.10566" class="Link-sc-1brdqhf-0 fWewSX">Exploring Simple Siamese Representation Learning (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/PatrickHua/SimSiam" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/aimagelab/show-control-and-tell" class="Link-sc-1brdqhf-0 fWewSX">Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://nerfies.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Deformable Neural Radiance Fields</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1812.01289" class="Link-sc-1brdqhf-0 fWewSX">Timeception for Complex Action Recognition (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/noureldien/timeception" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://programmingcomputervision.com/" class="Link-sc-1brdqhf-0 fWewSX">Programming Computer Vision with Python (2014)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/jesolem/PCV" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/nico/cvbook" class="Link-sc-1brdqhf-0 fWewSX">Notes</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" class="Link-sc-1brdqhf-0 fWewSX">Fast and Accurate One-Stage Space-Time Video Super-Resolution (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://alexyu.net/pixelnerf/" class="Link-sc-1brdqhf-0 fWewSX">pixelNeRF: Neural Radiance Fields from One or Few Images (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/sxyu/pixel-nerf" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Media-Smart/vedadet" class="Link-sc-1brdqhf-0 fWewSX">vedadet</a> - Single stage object detector toolbox based on PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/PeizeSun/OneNet" class="Link-sc-1brdqhf-0 fWewSX">OneNet: End-to-End One-Stage Object Detection by Classification Cost</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/consistent_depth" class="Link-sc-1brdqhf-0 fWewSX">Consistent Video Depth Estimation</a> - Estimate dense, flicker-free, geometrically consistent depth from monocular video, for example hand-held cell phone video.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vsitzmann/siren" class="Link-sc-1brdqhf-0 fWewSX">Implicit Neural Representations with Periodic Activation Functions</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.computationalimaging.org/" class="Link-sc-1brdqhf-0 fWewSX">Computational Imaging Stanford Lab</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ZHKKKe/MODNet" class="Link-sc-1brdqhf-0 fWewSX">Trimap-Free Solution for Portrait Matting in Real Time</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Fyusion/LLFF" class="Link-sc-1brdqhf-0 fWewSX">Local Light Field Fusion</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/gjy3035/Awesome-Crowd-Counting" class="Link-sc-1brdqhf-0 fWewSX">Awesome Crowd Counting</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/NSVF" class="Link-sc-1brdqhf-0 fWewSX">Neural Sparse Voxel Fields (NSVF)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.15126" class="Link-sc-1brdqhf-0 fWewSX">One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/goodfellow_ian/status/1333845997697388544" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/SharpAI/DeepCamera" class="Link-sc-1brdqhf-0 fWewSX">SharpAI DeepCamera</a> - Source stack for machine learning engineering with private deployment and AutoML for edge computing. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=25368272" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/krishnabits001/domain_specific_cl" class="Link-sc-1brdqhf-0 fWewSX">Contrastive learning of global and local features for medical image segmentation with limited annotations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2012.07810" class="Link-sc-1brdqhf-0 fWewSX">Real-Time High-Resolution Background Matting (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/PeterL1n/BackgroundMattingV2" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/KaiyangZhou/deep-person-reid" class="Link-sc-1brdqhf-0 fWewSX">Torchreid</a> - Deep learning person re-identification in PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mangye16/Unsupervised_Embedding_Learning" class="Link-sc-1brdqhf-0 fWewSX">Unsupervised Embedding Learning via Invariant and Spreading Instance Feature</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vitoralbiero/img2pose" class="Link-sc-1brdqhf-0 fWewSX">img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection" class="Link-sc-1brdqhf-0 fWewSX">SSD: Single Shot MultiBox Detector | a PyTorch Tutorial to Object Detection</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/2012.09688.pdf" class="Link-sc-1brdqhf-0 fWewSX">PCT: Point Cloud Transformer (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/MenghaoGuo/PCT" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2012.09161" class="Link-sc-1brdqhf-0 fWewSX">Learning Continuous Image Representation with Local Implicit Image Function (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/yinboc/liif" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/openvinotoolkit/cvat" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision Annotation Tool (CVAT)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/deit" class="Link-sc-1brdqhf-0 fWewSX">DeiT: Data-efficient Image Transformers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vsitzmann/awesome-implicit-representations" class="Link-sc-1brdqhf-0 fWewSX">Awesome Implicit Neural Representations</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/OlafenwaMoses/ImageAI" class="Link-sc-1brdqhf-0 fWewSX">ImageAI</a> - Python library built to empower developers to build applications and systems with self-contained Computer Vision capabilities. (<a target="_blank" rel="noopener noreferrer" href="http://imageai.org/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://raivn.cs.washington.edu/" class="Link-sc-1brdqhf-0 fWewSX">RAIVN Lab</a> - Reasoning, AI and VisioN (RAIVN) Lab. (<a target="_blank" rel="noopener noreferrer" href="https://github.com/RAIVNLab" class="Link-sc-1brdqhf-0 fWewSX">GitHub</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tryolabs/norfair" class="Link-sc-1brdqhf-0 fWewSX">Norfair</a> - Customizable lightweight Python library for real-time 2D object tracking.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sunshineatnoon/PytorchWCT" class="Link-sc-1brdqhf-0 fWewSX">Universal Style Transfer in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/NVIDIA/Dataset_Synthesizer" class="Link-sc-1brdqhf-0 fWewSX">NVIDIA Deep learning Dataset Synthesizer (NDDS)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/" class="Link-sc-1brdqhf-0 fWewSX">Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/mtli/HTML4Vision" class="Link-sc-1brdqhf-0 fWewSX">HTML4Vision</a> - Simple HTML visualization tool for computer vision research.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/taldatech/soft-intro-vae-pytorch" class="Link-sc-1brdqhf-0 fWewSX">Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/CompVis/taming-transformers" class="Link-sc-1brdqhf-0 fWewSX">Taming Transformers for High-Resolution Image Synthesis</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Sense-X/X-Temporal" class="Link-sc-1brdqhf-0 fWewSX">X-Temporal</a> - Easily implement SOTA video understanding methods with PyTorch on multiple machines and GPUs.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/RangiLyu/nanodet" class="Link-sc-1brdqhf-0 fWewSX">NanoDet</a> - Super fast and lightweight anchor-free object detection model. Real-time on mobile devices.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rwightman/pytorch-image-models" class="Link-sc-1brdqhf-0 fWewSX">PyTorch Image Models</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sangminwoo/awesome-vision-and-language" class="Link-sc-1brdqhf-0 fWewSX">Awesome Vision and Language</a> - Curated list of awesome vision and language resources.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1810.12890v1" class="Link-sc-1brdqhf-0 fWewSX">DropBlock: A regularization method for convolutional networks (2018)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/miguelvr/dropblock" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/FrancescoSaverioZuppichini/glasses" class="Link-sc-1brdqhf-0 fWewSX">Glasses</a> - Compact, concise and customizable deep learning computer vision library. (<a target="_blank" rel="noopener noreferrer" href="https://francescosaveriozuppichini.github.io/glasses-webapp/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/YuvalBahat/Explorable-Super-Resolution" class="Link-sc-1brdqhf-0 fWewSX">Explorable Super Resolution (2019)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Breakthrough/PySceneDetect" class="Link-sc-1brdqhf-0 fWewSX">PySceneDetect</a> - Python and OpenCV-based scene cut/transition detection program &amp; library.</li><li><a target="_blank" rel="noopener noreferrer" href="https://phaseai.com/resources/computer-vision-best-practices" class="Link-sc-1brdqhf-0 fWewSX">Best Practices for Building Computer Vision Models (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dbolya/tide" class="Link-sc-1brdqhf-0 fWewSX">TIDE</a> - General Toolbox for Identifying Object Detection Errors.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.12450" class="Link-sc-1brdqhf-0 fWewSX">Sparse R-CNN: End-to-End Object Detection with Learnable Proposals (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/PeizeSun/SparseR-CNN" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/haltakov/natural-language-image-search" class="Link-sc-1brdqhf-0 fWewSX">Unsplash Image Search</a> - Search photos on Unsplash using natural language.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/MIT-SPARK/Kimera-Semantics" class="Link-sc-1brdqhf-0 fWewSX">Kimera Semantics</a> - Real-Time 3D Semantic Reconstruction from 2D data.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ethz-asl/voxblox-plusplus" class="Link-sc-1brdqhf-0 fWewSX">Voxblox++</a> - Volumetric object-level semantic mapping framework.</li><li><a target="_blank" rel="noopener noreferrer" href="https://nv-tlabs.github.io/nglod/" class="Link-sc-1brdqhf-0 fWewSX">Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Surfaces</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/nv-tlabs/nglod" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/" class="Link-sc-1brdqhf-0 fWewSX">Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/nonrigid_nerf" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html" class="Link-sc-1brdqhf-0 fWewSX">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/DeepSDF" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/yenchenlin/awesome-NeRF" class="Link-sc-1brdqhf-0 fWewSX">Awesome Neural Radiance Fields</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/JialeCao001/D2Det" class="Link-sc-1brdqhf-0 fWewSX">D2Det: Towards High Quality Object Detection and Instance Segmentation (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2102.04803" class="Link-sc-1brdqhf-0 fWewSX">DetCo: Unsupervised Contrastive Learning for Object Detection (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/xieenze/DetCo" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kuzand/Computer-Vision-Video-Lectures" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision Video Lectures</a> - Curated list of free, high-quality, university-level courses with video lectures related to the field of Computer Vision.</li><li><a target="_blank" rel="noopener noreferrer" href="https://cord.tech/" class="Link-sc-1brdqhf-0 fWewSX">Cord</a> - Training data toolbox for computer vision. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26104104" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/orpatashnik/StyleCLIP" class="Link-sc-1brdqhf-0 fWewSX">Text-Guided Editing of Images (Using CLIP and StyleGAN)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pytorch/vision" class="Link-sc-1brdqhf-0 fWewSX">torchvision</a> - Datasets, Transforms and Models specific to Computer Vision. (<a target="_blank" rel="noopener noreferrer" href="https://paperswithcode.com/lib/torchvision" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2102.02371" class="Link-sc-1brdqhf-0 fWewSX">MeInGame: Create a Game Character Face from a Single Portrait (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/FuxiCV/MeInGame" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/kjw0612/awesome-deep-vision" class="Link-sc-1brdqhf-0 fWewSX">Awesome Deep Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dvschultz/dataset-tools" class="Link-sc-1brdqhf-0 fWewSX">dataset-tools</a> - Tools for quickly normalizing image datasets.</li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/" class="Link-sc-1brdqhf-0 fWewSX">Using Streamlit to visualize object detection output (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/mobile-vision" class="Link-sc-1brdqhf-0 fWewSX">Mobile Computer Vision @ Facebook</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/hasty-ai/opening-the-black-box-of-vision-ai-algorithms-466fc3d4bf78" class="Link-sc-1brdqhf-0 fWewSX">Opening the black box of vision AI algorithms (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/exadel-inc/CompreFace" class="Link-sc-1brdqhf-0 fWewSX">CompreFace</a> - Free face recognition solution that can be easily integrated into any IT system without prior machine learning skills.</li><li><a target="_blank" rel="noopener noreferrer" href="https://ibrnet.github.io/" class="Link-sc-1brdqhf-0 fWewSX">IBRNet: Learning Multi-View Image-Based Rendering (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1812.03506" class="Link-sc-1brdqhf-0 fWewSX">From Coarse to Fine: Robust Hierarchical Localization at Large Scale (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ethz-asl/hfnet" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://roboalgorithms.com/posts/camera-response-function/" class="Link-sc-1brdqhf-0 fWewSX">Camera Response Function (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2008.03713" class="Link-sc-1brdqhf-0 fWewSX">I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/mks0601/I2L-MeshNet_RELEASE" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.09485" class="Link-sc-1brdqhf-0 fWewSX">SkipNet: Learning Dynamic Routing in Convolutional Networks (2018)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ucbdrive/skipnet" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://mrcal.secretsauce.net/" class="Link-sc-1brdqhf-0 fWewSX">Mrcal</a> - Camera Calibrations and More. (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26300118" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1806.01260" class="Link-sc-1brdqhf-0 fWewSX">Digging Into Self-Supervised Monocular Depth Estimation (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/nianticlabs/monodepth2" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/vissl" class="Link-sc-1brdqhf-0 fWewSX">VISSL</a> - FAIR&#x27;s library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. (<a target="_blank" rel="noopener noreferrer" href="https://vissl.ai/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.zumolabs.ai/" class="Link-sc-1brdqhf-0 fWewSX">Zumo Labs</a> - Generate custom synthetic data sets that result in more robust and reliable computer vision models. (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ZumoLabs" class="Link-sc-1brdqhf-0 fWewSX">GitHub</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2008.07043" class="Link-sc-1brdqhf-0 fWewSX">Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/yijingru/BBAVectors-Oriented-Object-Detection" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.03206" class="Link-sc-1brdqhf-0 fWewSX">Perceiver: General Perception with Iterative Attention (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/lucidrains/perceiver-pytorch" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision" class="Link-sc-1brdqhf-0 fWewSX">SEER: The start of a more powerful, flexible, and accessible era for computer vision (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://gafniguy.github.io/4D-Facial-Avatars/" class="Link-sc-1brdqhf-0 fWewSX">NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://neural-3d-video.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Neural 3D Video Synthesis</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.06255" class="Link-sc-1brdqhf-0 fWewSX">Involution: Inverting the Inherence of Convolution for Visual Recognition (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/d-li14/involution" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Wangt-CN/Awesome-Causality-in-CV" class="Link-sc-1brdqhf-0 fWewSX">Awesome Causality in Computer Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.13413" class="Link-sc-1brdqhf-0 fWewSX">Vision Transformers for Dense Prediction (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/intel-isl/DPT" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.00680" class="Link-sc-1brdqhf-0 fWewSX">LoFTR: Detector-Free Local Feature Matching with Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/zju3dv/LoFTR" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/liuliu/ccv" class="Link-sc-1brdqhf-0 fWewSX">ccv</a> - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.13084" class="Link-sc-1brdqhf-0 fWewSX">Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengqili/Neural-Scene-Flow-Fields" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://xbpeng.github.io/projects/AMP/" class="Link-sc-1brdqhf-0 fWewSX">AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/xbpeng4/status/1379465757688352769" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://healeycodes.com/computer-vision-and-embroidery/" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision and Embroidery (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/healeycodes/embroidery-vision" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://jonbarron.info/mipnerf/" class="Link-sc-1brdqhf-0 fWewSX">mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://twitter.com/svpino/status/1379666495811117062" class="Link-sc-1brdqhf-0 fWewSX">Python libraries I use every day for computer vision work (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Soldelli/Awesome-Temporal-Language-Grounding-in-Videos" class="Link-sc-1brdqhf-0 fWewSX">Awesome Temporal Sentence Grounding in Videos</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://authentic.sice.indiana.edu/publications/Su_Crandall-AffectiveGrowthCV-CVPR21.pdf" class="Link-sc-1brdqhf-0 fWewSX">The Affective Growth of Computer Vision</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2008.05711" class="Link-sc-1brdqhf-0 fWewSX">Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/nv-tlabs/lift-splat-shoot" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.14503" class="Link-sc-1brdqhf-0 fWewSX">End-to-End Video Instance Segmentation with Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Epiphqny/VisTR" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/obss/sahi" class="Link-sc-1brdqhf-0 fWewSX">SAHI: Slicing Aided Hyper Inference</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.gamasutra.com/blogs/RobertPepperell/20200527/363615/FOVO_A_new_3D_rendering_technique_based_on_human_vision.php" class="Link-sc-1brdqhf-0 fWewSX">FOVO: A new 3D rendering technique based on human vision (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26795290" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2102.05095" class="Link-sc-1brdqhf-0 fWewSX">Is Space-Time Attention All You Need for Video Understanding? (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/TimeSformer" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/dk-liang/Awesome-Visual-Transformer" class="Link-sc-1brdqhf-0 fWewSX">Awesome Visual-Transformer</a> - Transformer with Computer-Vision (CV) papers.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/pytorchvideo" class="Link-sc-1brdqhf-0 fWewSX">PyTorchVideo</a> - Deep learning library for video understanding research. (<a target="_blank" rel="noopener noreferrer" href="https://pytorchvideo.org/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://charigyang.github.io/motiongroup/" class="Link-sc-1brdqhf-0 fWewSX">Self-supervised Video Object Segmentation by Motion Grouping (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26842018" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/torchvideo/torchvideo" class="Link-sc-1brdqhf-0 fWewSX">torchvideo</a> - Datasets, transforms and samplers for video in PyTorch.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1701.03077" class="Link-sc-1brdqhf-0 fWewSX">A General and Adaptive Robust Loss Function (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/jonbarron/robust_loss_pytorch" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://geyixiao.com/projects/sfrs" class="Link-sc-1brdqhf-0 fWewSX">Self-supervising Fine-grained Region Similarities for Large-scale Image Localization (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/yxgeee/OpenIBL" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://ai.googleblog.com/2021/04/max-deeplab-dual-path-transformers-for.html" class="Link-sc-1brdqhf-0 fWewSX">MaX-DeepLab: Dual-Path Transformers for End-to-End Panoptic Segmentation (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://vizycam.com/" class="Link-sc-1brdqhf-0 fWewSX">Vizy</a> - AI Camera.</li><li><a target="_blank" rel="noopener noreferrer" href="https://casual-effects.com/research/McGuire2021PixelArt/McGuire2021PixelArt.pdf" class="Link-sc-1brdqhf-0 fWewSX">MMPX Style-Preserving Pixel Art Magnification (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26934973" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://hkchengrex.github.io/MiVOS/" class="Link-sc-1brdqhf-0 fWewSX">Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/hkchengrex/Scribble-to-Mask" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1712.07629" class="Link-sc-1brdqhf-0 fWewSX">SuperPoint: Self-Supervised Interest Point Detection and Description (2018)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/eric-yyjau/pytorch-superpoint" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2102.02808" class="Link-sc-1brdqhf-0 fWewSX">Multi-Stage Progressive Image Restoration (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/swz30/MPRNet" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/colmap/colmap" class="Link-sc-1brdqhf-0 fWewSX">COLMAP</a> - General-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline with a graphical and command-line interface. (<a target="_blank" rel="noopener noreferrer" href="https://colmap.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/tzutalin/awesome-visual-slam" class="Link-sc-1brdqhf-0 fWewSX">Awesome Vision-based SLAM / Visual Odometry</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.03230" class="Link-sc-1brdqhf-0 fWewSX">Barlow Twins: Self-Supervised Learning via Redundancy Reduction (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/barlowtwins" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/cpc/hipcl" class="Link-sc-1brdqhf-0 fWewSX">HIPCL</a> - OpenCL/SPIR-V implementation of HIP.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/open-mmlab/mmcv" class="Link-sc-1brdqhf-0 fWewSX">MMCV</a> - Foundational library for computer vision research and supports many research projects. (<a target="_blank" rel="noopener noreferrer" href="https://mmcv.readthedocs.io/en/latest/" class="Link-sc-1brdqhf-0 fWewSX">Docs</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.12763" class="Link-sc-1brdqhf-0 fWewSX">MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ashkamath/mdetr" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.13963" class="Link-sc-1brdqhf-0 fWewSX">Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/suncet" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.14294" class="Link-sc-1brdqhf-0 fWewSX">Emerging Properties in Self-Supervised Vision Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/dino" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/i/lists/1351120526220152839" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>) (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/schrep/status/1388189398496202752" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.07652" class="Link-sc-1brdqhf-0 fWewSX">Geometry-Free View Synthesis: Transformers and no 3D Priors (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/CompVis/geometry-free-view-synthesis" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://minimaxir.com/2021/04/styleclip/" class="Link-sc-1brdqhf-0 fWewSX">Easily Transform Portraits of People into AI Aberrations Using StyleCLIP (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2102.09105" class="Link-sc-1brdqhf-0 fWewSX">DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Colin97/DeepMetaHandles" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/onepanelio/onepanel" class="Link-sc-1brdqhf-0 fWewSX">Onepanel</a> - Open and extensible integrated development environment (IDE) for computer vision. (<a target="_blank" rel="noopener noreferrer" href="https://docs.onepanel.ai/" class="Link-sc-1brdqhf-0 fWewSX">Web</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.12229" class="Link-sc-1brdqhf-0 fWewSX">Vector Neurons: A General Framework for SO(3)-Equivariant Networks (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/FlyingGiraffe/vnn" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.00637" class="Link-sc-1brdqhf-0 fWewSX">ISTR: End-to-End Instance Segmentation with Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/hujiecpp/ISTR" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.01601" class="Link-sc-1brdqhf-0 fWewSX">MLP-Mixer: An all-MLP Architecture for Vision (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/lucidrains/mlp-mixer-pytorch" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/rishikksh20/MLP-Mixer-pytorch" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/The-AI-Summer/self-attention-cv" class="Link-sc-1brdqhf-0 fWewSX">Self-attention building blocks for computer vision applications in PyTorch</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/LeViT" class="Link-sc-1brdqhf-0 fWewSX">LeViT: a Vision Transformer in ConvNet&#x27;s Clothing for Faster Inference</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.14631" class="Link-sc-1brdqhf-0 fWewSX">Text2Video: Text-driven Talking-head Video Synthesis with Phonetic Dictionary (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.unite.ai/neural-rendering-low-resolution-input-intel/" class="Link-sc-1brdqhf-0 fWewSX">Neural Rendering: How Low Can You Go in Terms of Input? (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://intel-isl.github.io/PhotorealismEnhancement/" class="Link-sc-1brdqhf-0 fWewSX">Enhancing Photorealism Enhancement (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.04619" class="Link-sc-1brdqhf-0 fWewSX">Paper</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/intel-isl/PhotorealismEnhancement" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://www.geometrylearning.com/DeepFaceEditing/" class="Link-sc-1brdqhf-0 fWewSX">DeepFaceEditing: Deep Face Generation and Editing with Disentangled Geometry and Appearance Control (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/IGLICT/DeepFaceEditing-Jittor" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://omnimatte.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Omnimatte: Associating Objects and Their Effects in Video (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.07576" class="Link-sc-1brdqhf-0 fWewSX">Rethinking &quot;Batch&quot; in BatchNorm (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rafaelpadilla/Object-Detection-Metrics" class="Link-sc-1brdqhf-0 fWewSX">Most popular metrics used to evaluate object detection algorithms</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2002.06353" class="Link-sc-1brdqhf-0 fWewSX">UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/UniVL" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/unrealcv/synthetic-computer-vision" class="Link-sc-1brdqhf-0 fWewSX">Synthetic for Computer Vision</a> - List of synthetic dataset and tools for computer vision.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Cartucho/vision_blender" class="Link-sc-1brdqhf-0 fWewSX">vision_blender</a> - Blender addon for generating synthetic ground truth data for Computer Vision applications.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/sicara/easy-few-shot-learning" class="Link-sc-1brdqhf-0 fWewSX">Easy Few-Shot Learning</a> - Ready-to-use code and tutorial notebooks to boost your way into few-shot image classification.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/xinntao/BasicSR" class="Link-sc-1brdqhf-0 fWewSX">BasicSR (Basic Super Restoration)</a> - Open source image and video restoration toolbox based on PyTorch, such as super-resolution, denoise, deblurring, JPEG artifacts removal, etc.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.10497" class="Link-sc-1brdqhf-0 fWewSX">Intriguing Properties of Vision Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/MachineLearning/comments/njm2ru/r_intriguing_properties_of_vision_transformers/" class="Link-sc-1brdqhf-0 fWewSX">Reddit</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.sbxrobotics.com/tutorial" class="Link-sc-1brdqhf-0 fWewSX">DIY Amazon Go – computer vision tutorial for cashierless checkout</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://matsui528.github.io/cvpr2020_tutorial_retrieval/" class="Link-sc-1brdqhf-0 fWewSX">Image Retrieval in the Wild (2020)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yutong-Zhou-cv/Awesome-Transformer-in-CV" class="Link-sc-1brdqhf-0 fWewSX">Awesome Transformer in CV papers</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.tangramvision.com/blog/calibration-from-scratch-using-rust-part-1-of-3" class="Link-sc-1brdqhf-0 fWewSX">Sensor Calibration from Scratch with Rust (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.tangramvision.com/" class="Link-sc-1brdqhf-0 fWewSX">Tangram Vision</a> - Integrate, Calibrate Perception Sensors For Robots, Drones &amp; Automation. (<a target="_blank" rel="noopener noreferrer" href="https://www.tangramvision.com/blog" class="Link-sc-1brdqhf-0 fWewSX">Blog</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/rust-cv/cv" class="Link-sc-1brdqhf-0 fWewSX">Rust CV</a> - Project to implement computer vision algorithms, abstractions, and systems in Rust.</li><li><a target="_blank" rel="noopener noreferrer" href="http://gvv.mpi-inf.mpg.de/projects/NeuralActor/" class="Link-sc-1brdqhf-0 fWewSX">Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=27393047" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2012.02107" class="Link-sc-1brdqhf-0 fWewSX">Robust Instance Segmentation through Reasoning about Multi-Object Occlusion (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/XD7479/Multi-Object-Occlusion" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.02636" class="Link-sc-1brdqhf-0 fWewSX">MERLOT: Multimodal Neural Script Knowledge Models (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/jmhessel/status/1401983972272345088" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.04560" class="Link-sc-1brdqhf-0 fWewSX">Scaling Vision Transformers (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2004.02788" class="Link-sc-1brdqhf-0 fWewSX">Self-Supervised Scene De-occlusion (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/XiaohangZhan/deocclusion" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.05744" class="Link-sc-1brdqhf-0 fWewSX">Pivotal Tuning for Latent-based Editing of Real Images (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/danielroich/PTI" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://flame.is.tue.mpg.de/" class="Link-sc-1brdqhf-0 fWewSX">FLAME: Articulated Expressive 3D Head Model</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Rubikplayer/flame-fitting" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.09681" class="Link-sc-1brdqhf-0 fWewSX">XCiT: Cross-Covariance Image Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/xcit" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://robust-cvd.github.io/" class="Link-sc-1brdqhf-0 fWewSX">Robust Consistent Video Depth Estimation (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/robust_cvd" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/Megvii-BaseDetection/cvpods" class="Link-sc-1brdqhf-0 fWewSX">cvpods</a> - All-in-one Toolbox for Computer Vision Research.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.10559" class="Link-sc-1brdqhf-0 fWewSX">CDFI: Compression-Driven Network Design for Frame Interpolation (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/tding1/CDFI" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://nerfmm.active.vision/" class="Link-sc-1brdqhf-0 fWewSX">NeRF--: Neural Radiance Fields Without Known Camera Parameters (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ActiveVisionLab/nerfmm" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.robots.ox.ac.uk/ActiveVision/" class="Link-sc-1brdqhf-0 fWewSX">Oxford Active Vision Laboratory</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ActiveVisionLab" class="Link-sc-1brdqhf-0 fWewSX">GitHub</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://szeliski.org/Book/" class="Link-sc-1brdqhf-0 fWewSX">Computer Vision: Algorithms and Applications, 2nd ed.</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ccrisan/motioneyeos" class="Link-sc-1brdqhf-0 fWewSX">motionEyeOS</a> - Linux distribution that turns your single board computer into a video surveillance system.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2107.02192" class="Link-sc-1brdqhf-0 fWewSX">Long-Short Transformer: Efficient Transformers for Language and Vision (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/lucidrains/long-short-transformer" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://distill.pub/2017/feature-visualization/" class="Link-sc-1brdqhf-0 fWewSX">Feature Visualization – How NNs understand images (2017)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1904.01906" class="Link-sc-1brdqhf-0 fWewSX">What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis (2019)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/clovaai/deep-text-recognition-benchmark" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.16831" class="Link-sc-1brdqhf-0 fWewSX">Convolutional Hough Matching Networks (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/juhongm999/chm" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/esvit" class="Link-sc-1brdqhf-0 fWewSX">Efficient Self-Supervised Vision Transformers (EsViT)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.10697" class="Link-sc-1brdqhf-0 fWewSX">ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/convit" class="Link-sc-1brdqhf-0 fWewSX">Code</a>) (<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=QdbieYXn_XM" class="Link-sc-1brdqhf-0 fWewSX">Paper Read</a>) (<a target="_blank" rel="noopener noreferrer" href="https://www.marktechpost.com/2021/07/20/facebook-ai-introduces-convit-a-computer-vision-model-that-improves-vision-transformers-vit-with-soft-convolutional-inductive-biases/" class="Link-sc-1brdqhf-0 fWewSX">Article</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/co3d" class="Link-sc-1brdqhf-0 fWewSX">CO3D: Common Objects In 3D</a> - Tools for working with the Common Objects in 3D (CO3D) dataset.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.03841" class="Link-sc-1brdqhf-0 fWewSX">ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/ORBIT-Dataset" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2106.13700" class="Link-sc-1brdqhf-0 fWewSX">Vision Transformer Architecture Search (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/xiusu/ViTAS" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2007.12072" class="Link-sc-1brdqhf-0 fWewSX">TSIT: A Simple and Versatile Framework for Image-to-Image Translation (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/EndlessSora/TSIT" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://machinelearning.apple.com/research/recognizing-people-photos" class="Link-sc-1brdqhf-0 fWewSX">Recognizing People in Photos Through Private On-Device Machine Learning (2021)</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2012.02047" class="Link-sc-1brdqhf-0 fWewSX">CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/CoCosNet-v2" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.10620" class="Link-sc-1brdqhf-0 fWewSX">HPNet: Deep Primitive Segmentation Using Hybrid Representations (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/SimingYan/HPNet" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/datature/portal" class="Link-sc-1brdqhf-0 fWewSX">Portal</a> - Fastest way to load and visualize your deep neural networks on images and videos.</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/cbsudux/awesome-human-pose-estimation" class="Link-sc-1brdqhf-0 fWewSX">Awesome Human Pose Estimation</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2004.03791" class="Link-sc-1brdqhf-0 fWewSX">Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/LongguangWang/ArbSR" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/omihub777/ViT-CIFAR" class="Link-sc-1brdqhf-0 fWewSX">PyTorch implementation for Vision Transformer</a></li><li><a target="_blank" rel="noopener noreferrer" href="http://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/index.html" class="Link-sc-1brdqhf-0 fWewSX">Repulsive Curves</a> - Model 2D &amp; 3D curves while avoiding self-intersection. (<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/keenanisalive/status/1422318272800829440" class="Link-sc-1brdqhf-0 fWewSX">Tweet</a>) (<a target="_blank" rel="noopener noreferrer" href="https://github.com/icethrush/repulsive-curves" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://chenlin9.github.io/SDEdit/" class="Link-sc-1brdqhf-0 fWewSX">SDEdit: Image Synthesis and Editing with Stochastic Differential Equations</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/ermongroup/SDEdit" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.12902" class="Link-sc-1brdqhf-0 fWewSX">Region Similarity Representation Learning (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Tete-Xiao/ReSim" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://nex-mpi.github.io/" class="Link-sc-1brdqhf-0 fWewSX">NeX: Real-time View Synthesis with Neural Basis Expansion (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/nex-mpi/nex-code" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://pengsongyou.github.io/conv_onet" class="Link-sc-1brdqhf-0 fWewSX">Convolutional Occupancy Networks (2020)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/autonomousvision/convolutional_occupancy_networks" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2104.02166" class="Link-sc-1brdqhf-0 fWewSX">Learning Optical Flow from a Few Matches (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/zacjiang/SCV" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2107.05790" class="Link-sc-1brdqhf-0 fWewSX">Visual Parser: Representing Part-whole Hierarchies with Transformers (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/kevin-ssy/ViP" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="http://jianghz.me/projects/superslomo/" class="Link-sc-1brdqhf-0 fWewSX">Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/avinashpaliwal/Super-SloMo" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2103.14641" class="Link-sc-1brdqhf-0 fWewSX">On Generating Transferable Targeted Perturbations (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/Muzammal-Naseer/TTP" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://github.com/bertjiazheng/awesome-scene-understanding" class="Link-sc-1brdqhf-0 fWewSX">Awesome Scene Understanding</a> - List of papers for scene understanding.</li><li><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2107.07651" class="Link-sc-1brdqhf-0 fWewSX">Align before Fuse: Vision and Language Representation Learning with Momentum Distillation (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/salesforce/ALBEF" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://depthoraclenerf.github.io/" class="Link-sc-1brdqhf-0 fWewSX">DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/DONERF" class="Link-sc-1brdqhf-0 fWewSX">Code</a>)</li><li><a target="_blank" rel="noopener noreferrer" href="https://www.strayrobots.io/blog/object-detection-in-an-hour" class="Link-sc-1brdqhf-0 fWewSX">Object Detection in an Hour (2021)</a> (<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=28100346" class="Link-sc-1brdqhf-0 fWewSX">HN</a>)</li></ul><div class="Box-nv15kw-0 kcFYCD"><h4 font-size="2" color="text.placeholder" class="Heading-sc-1cjoo9h-0 gQDpKH"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 iMUfwd" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>LINKS TO THIS PAGE</h4><ul style="padding-left:16px;list-style:none" class="list__List-sc-s5kxp2-0 clNcHj"><li class="reference-li__ReferenceLi-sc-1rtyfvw-0 bQueYM"><span data-test="ref-tag" class="Text-sc-1s3uzov-0 fbtryb"><span class="Text-sc-1s3uzov-0 eYnlOv"></span><a sx="[object Object]" class="Link-sc-1brdqhf-0 bclAhw" href="/SUMMARY/">Summary</a><button display="inline-block,inline-block,inline-block,none" class="ButtonBase-sc-181ps9o-0 Button-xjtz72-0 kNqLJV fyGPIN"><svg aria-hidden="true" role="img" class="octicon octicon-zap" viewBox="0 0 16 16" width="14" height="14" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg></button><span class="Text-sc-1s3uzov-0 dNDjBz"></span></span></li></ul></div><div class="Box-nv15kw-0 WreGk"><div display="flex" class="Box-nv15kw-0 eQVcYH"><a href="https://github.com/theowenyoung/gatsby-theme-primer-wiki/tree/main/example/content/computer-graphics/computer-vision/computer-vision.md" class="Link-sc-1brdqhf-0 jiMAyG"><svg aria-hidden="true" role="img" class="StyledOcticon-uhnt7w-0 dirTPa" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit this page</a><div><span font-size="1" color="auto.gray.7" class="Text-sc-1s3uzov-0 bikSBW">Last updated on<!-- --> <b>8/21/2021</b></span></div></div></div></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/computer-graphics/computer-vision/computer-vision/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-49a923993c744f4a3e64.js"],"app":["/app-cced7f1f6141af0d4cc8.js"],"component---theme-src-pages-404-js":["/component---theme-src-pages-404-js-384a8583460322aaad5b.js"],"component---theme-src-templates-post-query-js":["/component---theme-src-templates-post-query-js-4a3352054e86ce1ce39f.js"]};/*]]>*/</script><script src="/polyfill-49a923993c744f4a3e64.js" nomodule=""></script><script src="/component---theme-src-templates-post-query-js-4a3352054e86ce1ce39f.js" async=""></script><script src="/app-cced7f1f6141af0d4cc8.js" async=""></script><script src="/commons-d4c182a2050629043f01.js" async=""></script><script src="/fba589a3-7e142401208b26326fdb.js" async=""></script><script src="/bac1b955-c7037fb56cfc5cbde018.js" async=""></script><script src="/framework-1d3d9aa5e841da8133c8.js" async=""></script><script src="/webpack-runtime-e630ae35d4e9aa0fd704.js" async=""></script></body></html>